{"cells":[{"cell_type":"markdown","id":"a9a3759c","metadata":{"papermill":{"duration":0.044023,"end_time":"2022-06-04T07:23:15.401530","exception":false,"start_time":"2022-06-04T07:23:15.357507","status":"completed"},"tags":[],"id":"a9a3759c"},"source":["# [UW-Madison GI Tract Image Segmentation](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/)\n","> Track healthy organs in medical scans to improve cancer treatment\n","\n","<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25\">"]},{"cell_type":"markdown","id":"c9c90fa6","metadata":{"papermill":{"duration":0.046377,"end_time":"2022-06-04T07:23:15.504164","exception":false,"start_time":"2022-06-04T07:23:15.457787","status":"completed"},"tags":[],"id":"c9c90fa6"},"source":["# A. Methodlogy  ðŸŽ¯\n","* In this notebook I'll demonstrate **2.5D** image Training for **Segmentation** with `tf.data`, `tfrecord` using `Tensorflow`. \n","* In a nutshell, **2.5D Image Training** is training of **3D** image like **2D** Image.  More about **2.5D** training is discussed later. 2.5D images can take leverage of the extra depth information like our typical RGB image. In this notebook I'll be using 3 channels with 2 strides for 2.5D images\n","* In this notebook, I'll be also re-implementing **[TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation](https://arxiv.org/pdf/2102.04306.pdf)** Model using Tensorflow.\n","* TFRecord dataset for **Segmentation** is created using [UWMGI: 2.5D TFRecord Data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-tfrecord-data) notebook.\n","* TFRecord files are created using **StratifiedGroupFold** to avoid data leakage due to `case` and to stratify `empty` and `non-empty` mask cases.\n","* This notebook is compatible for both **GPU** and **TPU**. Device is automatically selected so you won't have to do anything to allocate device.\n","* As there are overlaps between **Stomach**, **Large Bowel** & **Small Bowel** classes, this is a **MultiLabel Segmentation** task, so final activaion should be `sigmoid` instead of `softmax`.\n","* You can play with different models and losses."]},{"cell_type":"markdown","id":"eae74778","metadata":{"papermill":{"duration":0.041721,"end_time":"2022-06-04T07:23:15.586936","exception":false,"start_time":"2022-06-04T07:23:15.545215","status":"completed"},"tags":[],"id":"eae74778"},"source":["# B. Notebooks ðŸ“’\n","ðŸ“Œ **2.5D-TransUNet**:\n","* Train: [UWMGI: TransUnet 2.5D [Train] [TF]](https://www.kaggle.com/awsaf49/uwmgi-transunet-2-5d-train-tf/)\n","<!-- * Infer:  UWMGI: TransUnet 2.5D [Infer] [TF]-->\n","\n","ðŸ“Œ **Data/Dataset**:\n","* Mask-Data: [UWMGI: Mask Data](https://www.kaggle.com/code/awsaf49/uwmgi-mask-data)\n","* Data: [UWMGI: 2.5D TFRecord Data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-tfrecord-data)\n","* Dataset: [UWMGI: 2.5D TFRecord Dataset](https://www.kaggle.com/datasets/awsaf49/uwmgi-25d-tfrecord-dataset)"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"LWFKvYUJ3Tcu"},"id":"LWFKvYUJ3Tcu"},{"cell_type":"code","source":[""],"metadata":{"id":"BJSqAB0J3SBT"},"id":"BJSqAB0J3SBT","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"0fb7d4db","metadata":{"papermill":{"duration":0.038733,"end_time":"2022-06-04T07:23:15.666020","exception":false,"start_time":"2022-06-04T07:23:15.627287","status":"completed"},"tags":[],"id":"0fb7d4db"},"source":["# 1. Install Libraries ðŸ› \n","Source code for TransUNet model is [here](https://github.com/awsaf49/TransUNet-tf)"]},{"cell_type":"code","source":["import os\n","# ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","os.chdir('/content/drive/MyDrive/open_directory/test/IMAGE')\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8h4Sk1GcT5b","executionInfo":{"status":"ok","timestamp":1657613166615,"user_tz":-540,"elapsed":25205,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"0faed0de-86bb-491e-fbd6-004655b5b187"},"id":"R8h4Sk1GcT5b","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/18A-45l2iGPLTzGSEx1Bd0wrE_qi8y2Ai/open_directory/test/IMAGE\n"]}]},{"cell_type":"code","execution_count":1,"id":"dd4217d6","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-06-04T07:23:15.756178Z","iopub.status.busy":"2022-06-04T07:23:15.755491Z","iopub.status.idle":"2022-06-04T07:23:48.844653Z","shell.execute_reply":"2022-06-04T07:23:48.843848Z","shell.execute_reply.started":"2022-05-19T11:11:17.906178Z"},"papermill":{"duration":33.140336,"end_time":"2022-06-04T07:23:48.844838","exception":false,"start_time":"2022-06-04T07:23:15.704502","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"dd4217d6","executionInfo":{"status":"ok","timestamp":1657613006093,"user_tz":-540,"elapsed":23021,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"22f6a854-8521-4996-9170-bc0a924d1b85"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |â–Ž                               | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |â–‹                               | 20 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |â–‰                               | 30 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–                              | 40 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Œ                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Š                              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆ                              | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–                             | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–‹                             | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆ                             | 102 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Ž                            | 112 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Œ                            | 122 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–‰                            | 133 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 143 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 153 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 163 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 174 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 184 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 194 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 204 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 215 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 225 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 235 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 245 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 256 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 266 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 276 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 286 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 296 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 307 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 317 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 327 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 337 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 348 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 358 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 368 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 378 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 389 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 399 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 409 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 419 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 430 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 440 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 450 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 460 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 471 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 481 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 491 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 501 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 512 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 522 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 532 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 542 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 552 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 563 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 573 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 583 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 593 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 604 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 614 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 624 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 634 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 645 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 655 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 665 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 675 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 686 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 696 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 706 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 716 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 727 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 737 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 747 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 757 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 768 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 778 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 788 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 798 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 808 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 819 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 829 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 839 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 849 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 860 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 870 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 880 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 890 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 901 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 911 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 921 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 931 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 942 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 952 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 962 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 972 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 983 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 993 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 7.0 MB/s \n","\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50 kB 3.4 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q transunet\n","!pip install -q segmentation_models\n"]},{"cell_type":"markdown","id":"962d7033","metadata":{"papermill":{"duration":0.040888,"end_time":"2022-06-04T07:23:48.926693","exception":false,"start_time":"2022-06-04T07:23:48.885805","status":"completed"},"tags":[],"id":"962d7033"},"source":["# 2. Import Libraries ðŸ“š\n","Let's imoport necessary libraries."]},{"cell_type":"code","source":["!pip install kaggle\n","!pip install kaggledatasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Te7q5BktXNm1","executionInfo":{"status":"ok","timestamp":1657613017805,"user_tz":-540,"elapsed":11718,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"080acac5-74ed-4cd7-95bf-1442799ad3cc"},"id":"Te7q5BktXNm1","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaggledatasets\n","  Downloading kaggledatasets-0.0.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from kaggledatasets) (1.5.12)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from kaggledatasets) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kaggledatasets) (1.21.6)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggledatasets) (1.24.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggledatasets) (2.23.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggledatasets) (2022.6.15)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggledatasets) (6.1.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggledatasets) (2.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggledatasets) (4.64.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggledatasets) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->kaggledatasets) (2022.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->kaggledatasets) (1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->kaggledatasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->kaggledatasets) (3.0.4)\n","Installing collected packages: kaggledatasets\n","Successfully installed kaggledatasets-0.0.1\n"]}]},{"cell_type":"code","execution_count":4,"id":"759d2c84","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-04T07:23:49.025726Z","iopub.status.busy":"2022-06-04T07:23:49.024988Z","iopub.status.idle":"2022-06-04T07:23:57.216591Z","shell.execute_reply":"2022-06-04T07:23:57.216027Z","shell.execute_reply.started":"2022-05-19T11:11:47.788817Z"},"papermill":{"duration":8.244642,"end_time":"2022-06-04T07:23:57.216744","exception":false,"start_time":"2022-06-04T07:23:48.972102","status":"completed"},"tags":[],"id":"759d2c84","executionInfo":{"status":"ok","timestamp":1657613061920,"user_tz":-540,"elapsed":443,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["import pandas as pd, numpy as np, random,os, shutil\n","import tensorflow as tf, re, math\n","import tensorflow_addons as tfa\n","import tensorflow.keras.backend as K\n","import efficientnet.tfkeras as efn\n","import sklearn\n","import cv2\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","import tensorflow_addons as tfa\n","import yaml\n","from IPython import display as ipd\n","import json\n","from datetime import datetime\n","\n","from glob import glob\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","from IPython import display as ipd\n","\n","# from kaggle_datasets import KaggleDatasets\n","import scipy\n","import warnings\n","\n","tfk = tf.keras\n","tfkl = tfk.layers\n","tfm = tf.math\n","\n","# Show less log messages\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(0)\n","\n","# Set tf.keras as backend\n","os.environ['SM_FRAMEWORK'] = 'tf.keras'\n","import segmentation_models as sm"]},{"cell_type":"markdown","id":"92c423b2","metadata":{"papermill":{"duration":0.043276,"end_time":"2022-06-04T07:23:57.301430","exception":false,"start_time":"2022-06-04T07:23:57.258154","status":"completed"},"tags":[],"id":"92c423b2"},"source":["# 3. Configuration âš™ï¸"]},{"cell_type":"code","execution_count":5,"id":"5cde16d4","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:23:57.395155Z","iopub.status.busy":"2022-06-04T07:23:57.394306Z","iopub.status.idle":"2022-06-04T07:23:57.396373Z","shell.execute_reply":"2022-06-04T07:23:57.396802Z","shell.execute_reply.started":"2022-05-19T11:11:55.630572Z"},"papermill":{"duration":0.055231,"end_time":"2022-06-04T07:23:57.396997","exception":false,"start_time":"2022-06-04T07:23:57.341766","status":"completed"},"tags":[],"id":"5cde16d4","executionInfo":{"status":"ok","timestamp":1657613067080,"user_tz":-540,"elapsed":451,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["class CFG:\n","    wandb = True\n","    competition = \"uwmgi-tf\"\n","    _wandb_kernel = \"awsaf49\"\n","    debug = False\n","    exp_name = \"v4\"\n","    comment = \"TransUNet-ResNet50V2-128x128-noaug-2.5D\"\n","\n","    # Use verbose=0 for silent, 1 for interactive\n","    verbose = 0\n","    display_plot = True\n","\n","    # Device for training\n","    device = None  # device is automatically selected\n","\n","    # Model & Backbone\n","    model_name = \"TransUNet\"\n","    backbone = \"ResNet50V2\"\n","\n","    # Seeding for reproducibility\n","    seed = 101\n","\n","    # Number of folds\n","    folds = 5\n","\n","    # Which Folds to train\n","    selected_folds = [0, 1, 2, 3, 4]\n","\n","    # Image Size\n","    img_size = [128, 128]\n","\n","    # Batch Size & Epochs\n","    batch_size = 32\n","    drop_remainder = False\n","    epochs = 15\n","    steps_per_execution = None\n","\n","    # Loss & Optimizer & LR Scheduler\n","    loss = \"dice_loss\"\n","    optimizer = \"Adam\"\n","    lr = 5e-4\n","    lr_schedule = \"CosineDecay\"\n","    patience = 5\n","\n","    # Augmentation\n","    augment = False\n","    transform = False\n","\n","    # Transformation\n","    fill_mode = \"constant\"\n","    rot = 5.0  # proprtional\n","    shr = 5.0  # proprtional\n","    hzoom = 100.0  # inv proportional\n","    wzoom = 100.0  # inv proportional\n","    hshift = 10.0  # proportional\n","    wshift = 10.0  # proportional\n","\n","    # Horizontal & Vertical Flip\n","    hflip = 0.5\n","    vflip = 0.5\n","\n","    # Clip values to [0, 1]\n","    clip = False\n","\n","    # CutOut\n","    drop_prob = 0.5\n","    drop_cnt = 10\n","    drop_size = 0.05\n","\n","    # Jitter\n","    sat = [0.7, 1.3]  # saturation\n","    cont = [0.8, 1.2]  # contrast\n","    bri = 0.15  # brightness\n","    hue = 0.0  # hue\n"]},{"cell_type":"markdown","id":"f810ea08","metadata":{"papermill":{"duration":0.040963,"end_time":"2022-06-04T07:23:57.479625","exception":false,"start_time":"2022-06-04T07:23:57.438662","status":"completed"},"tags":[],"id":"f810ea08"},"source":["# 4. Reproducibility â™»ï¸\n","Sets value for random seed to produce similar result in each run."]},{"cell_type":"code","execution_count":6,"id":"0a096276","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:23:57.563308Z","iopub.status.busy":"2022-06-04T07:23:57.562673Z","iopub.status.idle":"2022-06-04T07:23:57.569751Z","shell.execute_reply":"2022-06-04T07:23:57.570321Z","shell.execute_reply.started":"2022-05-19T11:11:55.646495Z"},"papermill":{"duration":0.050657,"end_time":"2022-06-04T07:23:57.570489","exception":false,"start_time":"2022-06-04T07:23:57.519832","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"0a096276","executionInfo":{"status":"ok","timestamp":1657613069015,"user_tz":-540,"elapsed":3,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"c4c2ba64-90aa-4211-8991-dab7c673f9e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["seeding done!!!\n"]}],"source":["def seeding(SEED):\n","    \"\"\"\n","    Sets all random seeds for the program (Python, NumPy, and TensorFlow).\n","    \"\"\"\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = str(SEED)\n","    tf.random.set_seed(SEED)\n","    print(\"seeding done!!!\")\n","\n","\n","seeding(CFG.seed)"]},{"cell_type":"markdown","id":"3d920646","metadata":{"papermill":{"duration":0.04114,"end_time":"2022-06-04T07:23:57.653389","exception":false,"start_time":"2022-06-04T07:23:57.612249","status":"completed"},"tags":[],"id":"3d920646"},"source":["# 5. Set Up Device ðŸ“±\n","Following codes automatically detects hardware(tpu or gpu or cpu). "]},{"cell_type":"code","execution_count":7,"id":"78d127ba","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:23:57.744392Z","iopub.status.busy":"2022-06-04T07:23:57.738932Z","iopub.status.idle":"2022-06-04T07:23:57.747511Z","shell.execute_reply":"2022-06-04T07:23:57.746839Z","shell.execute_reply.started":"2022-05-19T11:11:55.688236Z"},"papermill":{"duration":0.052988,"end_time":"2022-06-04T07:23:57.747679","exception":false,"start_time":"2022-06-04T07:23:57.694691","status":"completed"},"tags":[],"id":"78d127ba","executionInfo":{"status":"ok","timestamp":1657613070227,"user_tz":-540,"elapsed":2,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["def configure_device():\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()  # connect to tpu cluster\n","        strategy = tf.distribute.TPUStrategy(tpu) # get strategy for tpu\n","        print('> Running on TPU ', tpu.master(), end=' | ')\n","        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n","        device='TPU'\n","    except: # otherwise detect GPUs\n","        tpu = None\n","        gpus = tf.config.list_logical_devices('GPU') # get logical gpus\n","        ngpu = len(gpus)\n","        if ngpu: # if number of GPUs are 0 then CPU\n","            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n","            print(\"> Running on GPU\", end=' | ')\n","            print(\"Num of GPUs: \", ngpu)\n","            device='GPU'\n","        else:\n","            print(\"> Running on CPU\")\n","            strategy = tf.distribute.get_strategy() # connect to single gpu or cpu\n","            device='CPU'\n","    return strategy, device, tpu"]},{"cell_type":"code","execution_count":8,"id":"7dd9189c","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:23:57.844403Z","iopub.status.busy":"2022-06-04T07:23:57.843672Z","iopub.status.idle":"2022-06-04T07:24:03.593509Z","shell.execute_reply":"2022-06-04T07:24:03.592842Z","shell.execute_reply.started":"2022-05-19T11:11:55.700491Z"},"papermill":{"duration":5.804651,"end_time":"2022-06-04T07:24:03.593651","exception":false,"start_time":"2022-06-04T07:23:57.789000","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"7dd9189c","executionInfo":{"status":"ok","timestamp":1657613070848,"user_tz":-540,"elapsed":622,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"509c6ca1-32e4-4017-fc96-b5553d36c556"},"outputs":[{"output_type":"stream","name":"stdout","text":["> Running on CPU\n","REPLICAS: 1\n"]}],"source":["strategy, CFG.device, tpu = configure_device()\n","AUTO = tf.data.experimental.AUTOTUNE\n","REPLICAS = strategy.num_replicas_in_sync\n","print(f'REPLICAS: {REPLICAS}')"]},{"cell_type":"markdown","id":"3f9b00d0","metadata":{"papermill":{"duration":0.043049,"end_time":"2022-06-04T07:24:03.679973","exception":false,"start_time":"2022-06-04T07:24:03.636924","status":"completed"},"tags":[],"id":"3f9b00d0"},"source":["# 6. Meta Data ðŸ“–\n","* Files\n","    * `train.csv` - IDs and masks for all training objects.\n","    * `sample_submission.csv` - a sample submission file in the correct format\n","    * `train/` - a folder of case/day folders, each containing slice images for a particular case on a given day.\n","\n","> **Note** that the image filenames include 4 numbers (ex. `276_276_1.63_1.63.png`). These four numbers are slice height / width (integers in pixels) and heigh/width pixel spacing (floating points in mm). The first two defines the resolution of the slide. The last two record the physical size of each pixel.\n","\n","* Columns\n","    * `id` - unique identifier for object\n","    * `class` - the predicted class for the object\n","    * `EncodedPixels` - RLE-encoded pixels for the identified object"]},{"cell_type":"code","execution_count":9,"id":"8ca6f2c1","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:03.770720Z","iopub.status.busy":"2022-06-04T07:24:03.770049Z","iopub.status.idle":"2022-06-04T07:24:03.773206Z","shell.execute_reply":"2022-06-04T07:24:03.772538Z","shell.execute_reply.started":"2022-05-19T11:12:01.925891Z"},"papermill":{"duration":0.050986,"end_time":"2022-06-04T07:24:03.773349","exception":false,"start_time":"2022-06-04T07:24:03.722363","status":"completed"},"tags":[],"id":"8ca6f2c1","executionInfo":{"status":"ok","timestamp":1657613074705,"user_tz":-540,"elapsed":1,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["import re\n","def count_data_items(filenames):\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)"]},{"cell_type":"markdown","id":"726f2b69","metadata":{"papermill":{"duration":0.043251,"end_time":"2022-06-04T07:24:03.860751","exception":false,"start_time":"2022-06-04T07:24:03.817500","status":"completed"},"tags":[],"id":"726f2b69"},"source":["To run code on **TPU** we need our data to be stored on **Google Cloud Storage**. Hence, we'll be needing **GCS_PATH** of our stored data. Worried about how we will get our data stored on **GCS**? \"Kaggle to the Rescue\" Kaggle provides a **GCS_PATH** for public datasets. Hence we can use it for training our model on **TPU**. Simply we have to use `KaggleDatasets()` to get `GCS_PATH` of our dataset."]},{"cell_type":"markdown","id":"5a1015a8","metadata":{"papermill":{"duration":0.041867,"end_time":"2022-06-04T07:24:04.569410","exception":false,"start_time":"2022-06-04T07:24:04.527543","status":"completed"},"tags":[],"id":"5a1015a8"},"source":["# 7. Data Augmentation ðŸŒˆ\n","> **Caution:** Unlike classification problem, we have to augment both **image** & **mask** otherwise it'll create faulty data as **mask** won't match its corresponding **image**.\n","\n","<img src=\"https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/data_aug/outputs/with_mask/aug_and_mask.png\" width=800>"]},{"cell_type":"markdown","id":"c54b28e7","metadata":{"papermill":{"duration":0.043145,"end_time":"2022-06-04T07:24:04.655848","exception":false,"start_time":"2022-06-04T07:24:04.612703","status":"completed"},"tags":[],"id":"c54b28e7"},"source":["## Used Augmentations\n","Some Augmentations that were used here are,\n","\n","* RandomFlip (Left-Right)\n","<img src=\"https://dataaspirant.com/wp-content/uploads/2020/08/5-horizontal-flip-technique.png\" width=400>\n","\n","* Random Rotation\n","<img src=\"https://dataaspirant.com/wp-content/uploads/2020/08/4-rotation-technique.png\" width=500>\n","\n","\n","* RandomBrightness\n","<img src=\"https://affine.ai/wp-content/uploads/2022/02/2.jpg\" width=400>\n","\n","* RndomContrast\n","<img src=\"https://affine.ai/wp-content/uploads/2022/02/3.jpg\" width=400>\n","\n","* Zoom\n","<img src=\"https://affine.ai/wp-content/uploads/2022/02/16.jpg\" width=400>\n","\n","* Cutout\n","<img src=\"https://i.ibb.co/3MKjW0t/cutout.png\" width=400>\n","\n","* Shear\n","<img src=\"https://imgaug.readthedocs.io/en/latest/_images/shearx.jpg\" width=500>"]},{"cell_type":"markdown","id":"500233b2","metadata":{"papermill":{"duration":0.041387,"end_time":"2022-06-04T07:24:04.740016","exception":false,"start_time":"2022-06-04T07:24:04.698629","status":"completed"},"tags":[],"id":"500233b2"},"source":["## Utility"]},{"cell_type":"code","execution_count":10,"id":"8efe1c9b","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:04.831046Z","iopub.status.busy":"2022-06-04T07:24:04.830362Z","iopub.status.idle":"2022-06-04T07:24:04.842259Z","shell.execute_reply":"2022-06-04T07:24:04.841555Z","shell.execute_reply.started":"2022-05-19T11:12:02.414186Z"},"papermill":{"duration":0.057431,"end_time":"2022-06-04T07:24:04.842410","exception":false,"start_time":"2022-06-04T07:24:04.784979","status":"completed"},"tags":[],"id":"8efe1c9b","executionInfo":{"status":"ok","timestamp":1657613080340,"user_tz":-540,"elapsed":2,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["def random_int(shape=[], minval=0, maxval=1):\n","    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.int32)\n","\n","\n","def random_float(shape=[], minval=0.0, maxval=1.0):\n","    rnd = tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n","    return rnd\n","\n","\n","def get_mat(shear, height_zoom, width_zoom, height_shift, width_shift):\n","    \"\"\"\n","    ref: https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords/\n","    \"\"\"\n","    # returns 3x3 transformmatrix which transforms indicies\n","\n","    # CONVERT DEGREES TO RADIANS\n","    # rotation = math.pi * rotation / 180.\n","    shear = math.pi * shear / 180.0\n","\n","    def get_3x3_mat(lst):\n","        return tf.reshape(tf.concat([lst], axis=0), [3, 3])\n","\n","    one = tf.constant([1], dtype=\"float32\")\n","    zero = tf.constant([0], dtype=\"float32\")\n","\n","    # SHEAR MATRIX\n","    c2 = tf.math.cos(shear)\n","    s2 = tf.math.sin(shear)\n","\n","    shear_matrix = get_3x3_mat([one, s2, zero, zero, c2, zero, zero, zero, one])\n","    # ZOOM MATRIX\n","    zoom_matrix = get_3x3_mat(\n","        [one / height_zoom, zero, zero, zero, one / width_zoom, zero, zero, zero, one]\n","    )\n","    # SHIFT MATRIX\n","    shift_matrix = get_3x3_mat(\n","        [one, zero, height_shift, zero, one, width_shift, zero, zero, one]\n","    )\n","\n","    return K.dot(\n","        shear_matrix, K.dot(zoom_matrix, shift_matrix)\n","    )  # K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n"]},{"cell_type":"markdown","id":"1f663d3f","metadata":{"papermill":{"duration":0.041446,"end_time":"2022-06-04T07:24:04.926235","exception":false,"start_time":"2022-06-04T07:24:04.884789","status":"completed"},"tags":[],"id":"1f663d3f"},"source":["## Augment Fn"]},{"cell_type":"code","execution_count":11,"id":"4ec27f72","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:05.015439Z","iopub.status.busy":"2022-06-04T07:24:05.014384Z","iopub.status.idle":"2022-06-04T07:24:05.052391Z","shell.execute_reply":"2022-06-04T07:24:05.052881Z","shell.execute_reply.started":"2022-05-19T11:12:02.431386Z"},"papermill":{"duration":0.084025,"end_time":"2022-06-04T07:24:05.053075","exception":false,"start_time":"2022-06-04T07:24:04.969050","status":"completed"},"tags":[],"id":"4ec27f72","executionInfo":{"status":"ok","timestamp":1657613081449,"user_tz":-540,"elapsed":511,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["def ShiftScaleRotate(image, mask=None, DIM=CFG.img_size, p=1.0):\n","    \"\"\"\n","    ref: https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords/\n","    \"\"\"\n","    if random_float() > p:\n","        return image, mask\n","    if DIM[0] > DIM[1]:\n","        diff = DIM[0] - DIM[1]\n","        pad = [diff // 2, diff // 2 + (1 if diff % 2 else 0)]\n","        image = tf.pad(image, [[0, 0], [pad[0], pad[1]], [0, 0]])\n","        NEW_DIM = DIM[0]\n","        if mask is not None:\n","            mask = tf.pad(mask, [[0, 0], [pad[0], pad[1]], [0, 0]])\n","    elif DIM[0] < DIM[1]:\n","        diff = DIM[1] - DIM[0]\n","        pad = [diff // 2, diff // 2 + (1 if diff % 2 else 0)]\n","        image = tf.pad(image, [[pad[0], pad[1]], [0, 0], [0, 0]])\n","        NEW_DIM = DIM[1]\n","        if mask is not None:\n","            mask = tf.pad(mask, [[pad[0], pad[1]], [0, 0], [0, 0]])\n","\n","    rot = CFG.rot * tf.random.normal([1], dtype=\"float32\")\n","    shr = CFG.shr * tf.random.normal([1], dtype=\"float32\")\n","    h_zoom = 1.0 + tf.random.normal([1], dtype=\"float32\") / CFG.hzoom\n","    w_zoom = 1.0 + tf.random.normal([1], dtype=\"float32\") / CFG.wzoom\n","    h_shift = CFG.hshift * tf.random.normal([1], dtype=\"float32\")\n","    w_shift = CFG.wshift * tf.random.normal([1], dtype=\"float32\")\n","\n","    transformation_matrix = tf.linalg.inv(\n","        get_mat(shr, h_zoom, w_zoom, h_shift, w_shift)\n","    )\n","    flat_tensor = tfa.image.transform_ops.matrices_to_flat_transforms(\n","        transformation_matrix\n","    )\n","    rotation = math.pi * rot / 180.0\n","\n","    image = tfa.image.transform(image, flat_tensor, fill_mode=CFG.fill_mode)\n","    image = tfa.image.rotate(image, -rotation, fill_mode=CFG.fill_mode)\n","    if mask is not None:\n","        mask = tfa.image.transform(mask, flat_tensor, fill_mode=CFG.fill_mode)\n","        mask = tfa.image.rotate(mask, -rotation, fill_mode=CFG.fill_mode)\n","\n","    if DIM[0] > DIM[1]:\n","        image = tf.reshape(image, [NEW_DIM, NEW_DIM, 3])\n","        image = image[:, pad[0] : -pad[1], :]\n","        if mask is not None:\n","            mask = tf.reshape(mask, [NEW_DIM, NEW_DIM, 3])\n","            mask = mask[:, pad[0] : -pad[1], :]\n","    elif DIM[1] > DIM[0]:\n","        image = tf.reshape(image, [NEW_DIM, NEW_DIM, 3])\n","        image = image[pad[0] : -pad[1], :, :]\n","        if mask is not None:\n","            mask = tf.reshape(mask, [NEW_DIM, NEW_DIM, 3])\n","            mask = mask[pad[0] : -pad[1], :, :]\n","\n","    image = tf.reshape(image, [*DIM, 3])\n","    if mask is not None:\n","        mask = tf.reshape(mask, [*DIM, 3])\n","    return image, mask\n","\n","\n","def CutOut(image, mask=None, DIM=CFG.img_size, PROBABILITY=0.6, CT=5, SZ=0.1):\n","    \"\"\"\n","    ref: https://www.kaggle.com/code/cdeotte/tfrecord-experiments-upsample-and-coarse-dropout\n","    \"\"\"\n","    # Input Image - is with shape [dim,dim,3] not of [None,dim,dim,3]\n","    # Probability\n","    P = tf.cast(random_float() < PROBABILITY, tf.int32)\n","    if (P == 0) | (CT == 0) | (SZ == 0):\n","        return image, mask\n","    # Iterate Through Each Sample of Batch\n","    for k in range(CT):\n","        # Choose Random Location\n","        x = tf.cast(tf.random.uniform([], 0, DIM[1]), tf.int32)\n","        y = tf.cast(tf.random.uniform([], 0, DIM[0]), tf.int32)\n","        # Compute Square for CutOut\n","        WIDTH = tf.cast(SZ * min(DIM), tf.int32) * P\n","        ya = tf.math.maximum(0, y - WIDTH // 2)\n","        yb = tf.math.minimum(DIM[0], y + WIDTH // 2)\n","        xa = tf.math.maximum(0, x - WIDTH // 2)\n","        xb = tf.math.minimum(DIM[1], x + WIDTH // 2)\n","        # CutOut Image\n","        one = image[ya:yb, 0:xa, :]\n","        two = tf.zeros([yb - ya, xb - xa, 3], dtype=image.dtype)\n","        three = image[ya:yb, xb : DIM[1], :]\n","        middle = tf.concat([one, two, three], axis=1)\n","        image = tf.concat([image[0:ya, :, :], middle, image[yb : DIM[0], :, :]], axis=0)\n","        image = tf.reshape(image, [*DIM, 3])\n","        # CutOut Mask\n","        if mask is not None:\n","            one = mask[ya:yb, 0:xa, :]\n","            two = tf.zeros([yb - ya, xb - xa, 3], dtype=mask.dtype)  # ch=3\n","            three = mask[ya:yb, xb : DIM[1], :]\n","            middle = tf.concat([one, two, three], axis=1)\n","            mask = tf.concat(\n","                [mask[0:ya, :, :], middle, mask[yb : DIM[0], :, :]], axis=0\n","            )\n","            mask = tf.reshape(mask, [*DIM, 3])  # ch=3\n","    return image, mask\n","\n","\n","def RandomJitter(img, hue, sat, cont, bri, p=1.0):\n","    if random_float() > p:\n","        return img\n","    img = tf.image.random_hue(img, hue)\n","    img = tf.image.random_saturation(img, sat[0], sat[1])\n","    img = tf.image.random_contrast(img, cont[0], cont[1])\n","    img = tf.image.random_brightness(img, bri)\n","    return img\n","\n","\n","def RandomFlip(img, msk=None, hflip_p=0.5, vflip_p=0.5):\n","    if random_float() < hflip_p:\n","        img = tf.image.flip_left_right(img)\n","        if msk is not None:\n","            msk = tf.image.flip_left_right(msk)\n","    if random_float() < vflip_p:\n","        img = tf.image.flip_up_down(img)\n","        if msk is not None:\n","            msk = tf.image.flip_up_down(msk)\n","    return img, msk"]},{"cell_type":"markdown","id":"4f3c9509","metadata":{"papermill":{"duration":0.043507,"end_time":"2022-06-04T07:24:05.139870","exception":false,"start_time":"2022-06-04T07:24:05.096363","status":"completed"},"tags":[],"id":"4f3c9509"},"source":["# 8. Data Pipeline ðŸš"]},{"cell_type":"markdown","id":"6a9354e4","metadata":{"papermill":{"duration":0.041483,"end_time":"2022-06-04T07:24:05.223264","exception":false,"start_time":"2022-06-04T07:24:05.181781","status":"completed"},"tags":[],"id":"6a9354e4"},"source":["## 2.5D Training\n","**What is 2.5D Training?**\n","\n","Even though we can do easy straight-forward 2D training, we can utilize ct slices for extra depth information. For example, we can stack consecutive slices of the scans to get a 3D volume. But one of the reasons why I'm inferring them as 2.5D is that we'll be training 3D images like 2D images. Those who haven't come across this method may get confused at first but let me explain. When we train 2D images like RGB images we actually pass a 3D tensor ex:`[None, channel, height, width]` to a model. For PyTorch, the last two dimensions are spacial(height & width) and the first one is the **channel** dimension. Now for the ct image, we don't have any channel information so we can use that dimension to **stack multiple ct scans as channels and train them as 2d images**. \n","\n","This method has some cool advantages over 3D training for instance,\n","* Low GPU/memory cost.\n","* Simple pipeline.\n","* Easier augmentation.\n","* Quick inference.\n","* Many open-source models.\n","\n","In my notebook, I've stacked 3 slices with stride=2, you can check the demo image above for example. It kinda looks like **3d movie scene in the theatre**. \n","\n","<div align=center><img src=\"https://i.ibb.co/sgsPf4v/Capture.png\" width=800></div>\n","<div align=center><img src=\"https://i.ibb.co/KKtZ7Gn/Picture1-3d.png\" width=500></div>"]},{"cell_type":"markdown","id":"59cf8bb2","metadata":{"papermill":{"duration":0.041494,"end_time":"2022-06-04T07:24:05.306591","exception":false,"start_time":"2022-06-04T07:24:05.265097","status":"completed"},"tags":[],"id":"59cf8bb2"},"source":["## Reading TFRecord Data\n","**What is TFRecord & Why use it for Segmentation?**\n","\n","* The `.tfrecord`/`.tfrec` format is TensorFlow's custom data format which is used for storing a sequence of binary records.\n","* For **Segmentation** unlike any other data formatk in `.tfrecord` we don't have to the read file twice (one for image and one for mask). In `tfrecord` we just have to read file once and we can access both image and mask.\n","* TFRecord consumes **less storage on disk**, and has **faster read and write time from the disk**, which makes it suitable for **segmentation** task.\n","* Apart from that there are a number of advantages to using TFRecords: \n","    * Efficient usage of storage.\n","    * Better I/O Speed.\n","    * TPUs require that you pass data to them in TFRecord format\n","    \n","**How TFRecord is created for Segmentation?**\n","\n","* Mask is stored in `tfrecord` exactly the same way as a image that is as a byte-string. \n","* So, you can easily access the both image and mask from example_proto using `exmple[\"image\"]` & `example[\"mask\"]`. \n","* Then, to decode it to `tf.Tensor` simply we can use `tf.io.decode_raw()` function.\n","* For more information, checout [UWMGI: 2.5D TFRecord Data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-tfrecord-data) notebook."]},{"cell_type":"code","execution_count":12,"id":"78c1106d","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2022-06-04T07:24:05.395709Z","iopub.status.busy":"2022-06-04T07:24:05.394705Z","iopub.status.idle":"2022-06-04T07:24:05.411920Z","shell.execute_reply":"2022-06-04T07:24:05.412385Z","shell.execute_reply.started":"2022-05-19T11:12:02.47224Z"},"papermill":{"duration":0.06416,"end_time":"2022-06-04T07:24:05.412567","exception":false,"start_time":"2022-06-04T07:24:05.348407","status":"completed"},"tags":[],"id":"78c1106d","executionInfo":{"status":"ok","timestamp":1657613083284,"user_tz":-540,"elapsed":2,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["# Decode image from bytestring to tensor\n","def decode_image(data, height, width, target_size=CFG.img_size):\n","    img = tf.io.decode_raw(data, out_type=tf.uint16)\n","    img = tf.reshape(img, [height, width, 3])  # explicit size needed for TPU\n","    img = tf.cast(img, tf.float32)\n","    img = tf.math.divide_no_nan(img, tf.math.reduce_max(img))  # scale image to [0, 1]\n","    img = tf.image.resize_with_pad(\n","        img, target_size[0], target_size[1], method=\"nearest\"\n","    )  # resize with pad to avoid distortion\n","    img = tf.reshape(img, [*target_size, 3])  # reshape after resize\n","    return img\n","\n","\n","# Decode mask from bytestring to tensor\n","def decode_mask(data, height, width, target_size=CFG.img_size):\n","    msk = tf.io.decode_raw(data, out_type=tf.uint8)\n","    msk = tf.reshape(msk, [height, width, 3])  # explicit size needed for TPU\n","    msk = tf.cast(msk, tf.float32)\n","    msk = msk / 255.0  # scale mask data to[0, 1]\n","    msk = tf.image.resize_with_pad(\n","        msk, target_size[0], target_size[1], method=\"nearest\"\n","    )\n","    msk = tf.reshape(msk, [*target_size, 3])  # reshape after resize\n","    return msk\n","\n","\n","# Read tfrecord data & parse it & do augmentation\n","def read_tfrecord(example, augment=True, return_id=False, dim=CFG.img_size):\n","    tfrec_format = {\n","        \"id\": tf.io.FixedLenFeature([], tf.string),\n","        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring\n","        \"height\": tf.io.FixedLenFeature([], tf.int64),\n","        \"width\": tf.io.FixedLenFeature([], tf.int64),\n","        \"mask\": tf.io.FixedLenFeature([], tf.string),\n","    }\n","    example = tf.io.parse_single_example(\n","        example, tfrec_format\n","    )  # parses a single example proto.\n","    image_id = example[\"id\"]\n","    height = example[\"height\"]\n","    width = example[\"width\"]\n","    img = decode_image(example[\"image\"], height, width, dim)  # access image\n","    msk = decode_mask(example[\"mask\"], height, width, dim)  # access mask\n","    if augment:  # do augmentation\n","        img, msk = ShiftScaleRotate(img, msk, DIM=dim, p=0.75)\n","        img, msk = RandomFlip(img, msk, hflip_p=CFG.hflip, vflip_p=CFG.vflip)\n","        img = RandomJitter(img, CFG.hue, CFG.sat, CFG.cont, CFG.bri, p=0.8)\n","        img, msk = CutOut(\n","            img,\n","            msk,\n","            DIM=dim,\n","            PROBABILITY=CFG.drop_prob,\n","            CT=CFG.drop_cnt,\n","            SZ=CFG.drop_size,\n","        )\n","    img = tf.clip_by_value(img, 0, 1) if CFG.clip else img\n","    img = tf.reshape(img, [*dim, 3])\n","    msk = tf.reshape(msk, [*dim, 3])\n","    return (img, msk) if not return_id else (img, image_id, msk)\n"]},{"cell_type":"markdown","id":"3102853c","metadata":{"papermill":{"duration":0.041254,"end_time":"2022-06-04T07:24:05.496799","exception":false,"start_time":"2022-06-04T07:24:05.455545","status":"completed"},"tags":[],"id":"3102853c"},"source":["## Pipeline with **tf.data**\n","<div align=center> <img src=\"https://storage.googleapis.com/jalammar-ml/tf.data/images/tf.data.png\" width=700></div>\n","\n","To build data pipeline using `tfrecrod/tfrec`, we need to use `tf.data` API.\n","\n","* We can build complex input pipelines from simple, reusable pieces using`tf.data` API . For example, the pipeline for an image model might aggregate data from files in a distributed file system, apply random transformation/augmentation to each image, and merge randomly selected images into a batch for training.\n","* Moreover `tf.data` API provides a `tf.data.Dataset` feature that represents a sequence of components where each component comprises one or more pieces. For instances, in an image pipeline, an component might be a single training example, with a pair of tensor pieces representing the image and its label.\n","\n","Checkout this [doc](https://www.tensorflow.org/guide/data) if you want to learn more about `tf.data`.\n","\n","## Pipeline\n","* Read **TFRecord** files.\n","* `cache` data to speed up the training.\n","* `repeat` the data stream (for training only & test-time augmentation).\n","* `shuffle` the data (for training only).\n","* Unparse **tfrecord** data & convert it to Image data from ByteString.\n","* Process Image & Mask.\n","* Apply Augmentations.\n","* Batch Data."]},{"cell_type":"code","execution_count":13,"id":"f56a3bdf","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:24:05.589574Z","iopub.status.busy":"2022-06-04T07:24:05.588581Z","iopub.status.idle":"2022-06-04T07:24:05.591971Z","shell.execute_reply":"2022-06-04T07:24:05.592441Z","shell.execute_reply.started":"2022-05-19T11:12:02.493619Z"},"papermill":{"duration":0.054156,"end_time":"2022-06-04T07:24:05.592624","exception":false,"start_time":"2022-06-04T07:24:05.538468","status":"completed"},"tags":[],"id":"f56a3bdf","executionInfo":{"status":"ok","timestamp":1657613083284,"user_tz":-540,"elapsed":1,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["def get_dataset(\n","    filenames,\n","    shuffle=True,\n","    repeat=True,\n","    augment=True,\n","    cache=True,\n","    return_id=False,\n","    batch_size=CFG.batch_size * REPLICAS,\n","    target_size=CFG.img_size,\n","    drop_remainder=False,\n","    seed=CFG.seed,\n","):\n","    dataset = tf.data.TFRecordDataset(\n","        filenames, num_parallel_reads=AUTO\n","    )  # read tfrecord files\n","    if cache:\n","        dataset = dataset.cache()  # cache data for speedup\n","    if repeat:\n","        dataset = dataset.repeat()  # repeat the data (for training only)\n","    if shuffle:\n","        dataset = dataset.shuffle(\n","            1024, seed=seed\n","        )  # shuffle the data (for training only)\n","        options = tf.data.Options()\n","        options.experimental_deterministic = (\n","            False  # order won't be maintained when we shuffle\n","        )\n","        dataset = dataset.with_options(options)\n","    dataset = dataset.map(\n","        lambda x: read_tfrecord(\n","            x,\n","            augment=augment,  # unparse tfrecord data with masks\n","            return_id=return_id,\n","            dim=target_size,\n","        ),\n","        num_parallel_calls=AUTO,\n","    )\n","    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)  # batch the data\n","    dataset = dataset.prefetch(AUTO)  # prefatch data for speedup\n","    return dataset"]},{"cell_type":"markdown","id":"c2e69f5d","metadata":{"papermill":{"duration":0.04378,"end_time":"2022-06-04T07:24:05.679704","exception":false,"start_time":"2022-06-04T07:24:05.635924","status":"completed"},"tags":[],"id":"c2e69f5d"},"source":["# 9. Visualization ðŸ”­\n","To ensure our pipeline is generating **image** and **mask** correctly, we'll check some samples from a batch."]},{"cell_type":"code","execution_count":14,"id":"36568d54","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:05.773650Z","iopub.status.busy":"2022-06-04T07:24:05.772993Z","iopub.status.idle":"2022-06-04T07:24:05.779709Z","shell.execute_reply":"2022-06-04T07:24:05.780266Z","shell.execute_reply.started":"2022-05-19T11:12:02.507544Z"},"papermill":{"duration":0.057771,"end_time":"2022-06-04T07:24:05.780448","exception":false,"start_time":"2022-06-04T07:24:05.722677","status":"completed"},"tags":[],"id":"36568d54","executionInfo":{"status":"ok","timestamp":1657613105136,"user_tz":-540,"elapsed":435,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","def display_batch(batch, row=2, col=5):\n","    imgs, msks = batch\n","    plt.figure(figsize=(2.5*col, 2.5*row))\n","    for idx in range(row*col):\n","        ax = plt.subplot(row, col, idx+1)\n","        img = imgs[idx].numpy()*255.0\n","        img = img.astype('uint8')\n","        for i in range(3):\n","            img[...,i] = clahe.apply(img[...,i])\n","        ax.imshow(img, cmap='bone')\n","        msk = msks[idx].numpy()\n","        ax.imshow(msk,alpha=0.4)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","    plt.tight_layout();\n","    plt.show();"]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMNqh2LFcPEN","executionInfo":{"status":"ok","timestamp":1657613123821,"user_tz":-540,"elapsed":618,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"a0e99f78-5a41-45ae-eb28-01c1dcfabb9b"},"id":"lMNqh2LFcPEN","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["import pickle\n","\n","with open(file='all_train_images.pickle', mode='rb') as f:\n","    ALL_FILENAMES = pickle.load(f)"],"metadata":{"id":"OpKK0JtGaiGd","executionInfo":{"status":"ok","timestamp":1657613167720,"user_tz":-540,"elapsed":1107,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"id":"OpKK0JtGaiGd","execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"id":"530c9257","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:24:05.869106Z","iopub.status.busy":"2022-06-04T07:24:05.868165Z","iopub.status.idle":"2022-06-04T07:24:14.479436Z","shell.execute_reply":"2022-06-04T07:24:14.479968Z","shell.execute_reply.started":"2022-05-19T11:12:02.522819Z"},"papermill":{"duration":8.657713,"end_time":"2022-06-04T07:24:14.480142","exception":false,"start_time":"2022-06-04T07:24:05.822429","status":"completed"},"tags":[],"id":"530c9257","outputId":"9d11d50d-d0ba-460b-9987-de449c14d517","colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"status":"error","timestamp":1657613178320,"user_tz":-540,"elapsed":10602,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[{"output_type":"error","ename":"DataLossError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-466a8bf474c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALL_FILENAMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'image_shape: {img.shape} mask_shape:{msk.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'image_dtype: {img.dtype} mask_dtype: {msk.dtype}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    820\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2921\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2923\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2924\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDataLossError\u001b[0m: corrupted record at 0 [Op:IteratorGetNext]"]}],"source":["ds = get_dataset(ALL_FILENAMES[:2], augment=False, cache=False, repeat=False).take(1)\n","batch = next(iter(ds.unbatch().batch(20)))\n","img, msk = batch\n","print(f'image_shape: {img.shape} mask_shape:{msk.shape}')\n","print(f'image_dtype: {img.dtype} mask_dtype: {msk.dtype}')\n","display_batch(batch)"]},{"cell_type":"markdown","id":"229abccc","metadata":{"papermill":{"duration":0.056786,"end_time":"2022-06-04T07:24:14.593154","exception":false,"start_time":"2022-06-04T07:24:14.536368","status":"completed"},"tags":[],"id":"229abccc"},"source":["# 10. Loss Fn ðŸ“‰\n","Some implemented loss_functions are,\n","* Dice Loss\n","$$ \n","Dice = \\frac{2\\cdot{TP}}{2\\cdot{TP} + FP + FN}\n","$$\n","* Tversky Loss (Modified IoU Loss)\n","$$ \n","IoU = \\frac{TP}{TP + FP + FN}\n","$$\n","$$\n","Tversky = \\frac{TP}{TP + \\alpha\\cdot{FP} + \\beta\\cdot{FN}}\n","$$\n","* Focal Tversky Loss (Focal Loss + Tversky Loss)\n","$$ \n","FocalTversky = (1 - Tversky)^\\gamma\n","$$"]},{"cell_type":"code","execution_count":20,"id":"89e61c26","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2022-06-04T07:24:14.721958Z","iopub.status.busy":"2022-06-04T07:24:14.721197Z","iopub.status.idle":"2022-06-04T07:24:14.724971Z","shell.execute_reply":"2022-06-04T07:24:14.724398Z","shell.execute_reply.started":"2022-05-19T11:12:09.544142Z"},"papermill":{"duration":0.075028,"end_time":"2022-06-04T07:24:14.725120","exception":false,"start_time":"2022-06-04T07:24:14.650092","status":"completed"},"tags":[],"id":"89e61c26","executionInfo":{"status":"ok","timestamp":1657613183387,"user_tz":-540,"elapsed":453,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["from segmentation_models.base import functional as F\n","import tensorflow.keras.backend as K\n","\n","kwargs = {}\n","kwargs[\"backend\"] = K  # set tensorflow.keras as backend\n","\n","\n","def dice_coef(y_true, y_pred):\n","    \"\"\"Dice coefficient\"\"\"\n","    dice = F.f_score(\n","        y_true,\n","        y_pred,\n","        beta=1,\n","        smooth=1e-5,\n","        per_image=False,\n","        threshold=0.5,\n","        **kwargs,\n","    )\n","    return dice\n","\n","\n","def tversky(y_true, y_pred, axis=(0, 1, 2), alpha=0.3, beta=0.7, smooth=0.0001):\n","    \"Tversky metric\"\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(y_pred, tf.float32)\n","    tp = tf.math.reduce_sum(y_true * y_pred, axis=axis) # calculate True Positive\n","    fn = tf.math.reduce_sum(y_true * (1 - y_pred), axis=axis) # calculate False Negative\n","    fp = tf.math.reduce_sum((1 - y_true) * y_pred, axis=axis) # calculate False Positive\n","    tv = (tp + smooth) / (tp + alpha * fn + beta * fp + smooth) # calculate tversky\n","    tv = tf.math.reduce_mean(tv)\n","    return tv\n","\n","\n","def tversky_loss(y_true, y_pred):\n","    \"Tversky Loss\"\n","    return 1 - tversky(y_true, y_pred)\n","\n","\n","def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n","    \"Focal Tversky Loss: Focal Loss + Tversky Loss\"\n","    tv = tversky(y_true, y_pred)\n","    return K.pow((1 - tv), gamma)\n","\n","\n","# Register custom objects\n","custom_objs = {\n","    \"dice_loss\": sm.losses.dice_loss,\n","    \"dice_coef\": dice_coef,\n","    \"bce_dice_loss\": sm.losses.bce_dice_loss,\n","    \"bce_jaccard_loss\": sm.losses.bce_jaccard_loss,\n","    \"tversky_loss\": tversky_loss,\n","    \"focal_tversky_loss\": focal_tversky_loss,\n","    \"jaccard_loss\": sm.losses.jaccard_loss,\n","    \"precision\": sm.metrics.precision,\n","    \"recall\": sm.metrics.recall,\n","}\n","tf.keras.utils.get_custom_objects().update(custom_objs)"]},{"cell_type":"markdown","id":"cff4f14b","metadata":{"papermill":{"duration":0.055266,"end_time":"2022-06-04T07:24:14.838648","exception":false,"start_time":"2022-06-04T07:24:14.783382","status":"completed"},"tags":[],"id":"cff4f14b"},"source":["# 11. LR Schedule âš“\n","* Learning Rate scheduler for transfer learning. \n","* The learning rate starts from `initial_learning_rate`, then decreases to a`minimum_learning_rate` using different methods namely,\n","    * **ReduceLROnPlateau**: Reduce lr when score isn't improving.\n","    * **CosineDecay**: Follow Cosine graph to reduce lr.\n","    * **ExponentialDecay**: Reduce lr exponentially."]},{"cell_type":"code","execution_count":21,"id":"4f143f50","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:24:14.962902Z","iopub.status.busy":"2022-06-04T07:24:14.961848Z","iopub.status.idle":"2022-06-04T07:24:14.964303Z","shell.execute_reply":"2022-06-04T07:24:14.964750Z","shell.execute_reply.started":"2022-05-19T11:12:09.559148Z"},"papermill":{"duration":0.067914,"end_time":"2022-06-04T07:24:14.964943","exception":false,"start_time":"2022-06-04T07:24:14.897029","status":"completed"},"tags":[],"id":"4f143f50","executionInfo":{"status":"ok","timestamp":1657613185585,"user_tz":-540,"elapsed":1,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["def get_lr_callback():\n","    if CFG.lr_schedule == \"ReduceLROnPlateau\":\n","        lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n","            monitor=\"val_loss\",\n","            factor=0.1,\n","            patience=int(CFG.patience / 2),\n","            min_lr=CFG.lr / 1e2,\n","        )\n","    elif CFG.lr_schedule == \"CosineDecay\":\n","        lr_schedule = tf.keras.experimental.CosineDecay(\n","            initial_learning_rate=CFG.lr, decay_steps=CFG.epochs + 2, alpha=CFG.lr / 1e2\n","        )\n","        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)\n","    elif CFG.lr_schedule == \"ExponentialDecay\":\n","        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","            initial_learning_rate=CFG.lr,\n","            decay_steps=CFG.epochs + 2,\n","            decay_rate=0.05,\n","            staircase=False,\n","        )\n","        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)\n","    return lr_schedule"]},{"cell_type":"markdown","id":"a215bdac","metadata":{"papermill":{"duration":0.055293,"end_time":"2022-06-04T07:24:15.076881","exception":false,"start_time":"2022-06-04T07:24:15.021588","status":"completed"},"tags":[],"id":"a215bdac"},"source":["# 12. TransUnet ðŸ¤–\n","> [TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation](https://arxiv.org/pdf/2102.04306.pdf)\n","\n","In a nutshell, this work shows how to convert a **UNet** into a so-called **TransUNet** by using a visual transformer (ViT) network in the encoder. Details of the architecture are in Figure below. As opposed to other methods which use a pure **transformer-based encoder** to convert the input image into a latent vector. A series of convolutions (much like in the original UNet) is used to convert the input image into a set of lower-resolution feature maps which are then encode with a ViT.\n","So, main components fo **TransUNet** are,\n","\n","1. Encoder (Pure or Hybrid)\n","    * CNN\n","    * Transformer\n","2. Decoder\n","    * CNN\n","3. Skip Connection in Hybrid\n","    * Connection betwween CNN Encoder & CNN Decoder\n","\n","> **Codes below are adapted from [here](https://github.com/kenza-bouzid/TransUnet)**\n","\n","<img src=\"https://production-media.paperswithcode.com/social-images/hfPJrzzvUuaeIMvb.png\" width=800>"]},{"cell_type":"markdown","id":"cb8bbcc5","metadata":{"papermill":{"duration":0.055097,"end_time":"2022-06-04T07:24:15.190413","exception":false,"start_time":"2022-06-04T07:24:15.135316","status":"completed"},"tags":[],"id":"cb8bbcc5"},"source":["## Utils\n","* Utility code to load `imagenet` weights"]},{"cell_type":"code","execution_count":22,"id":"f738388e","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:15.304992Z","iopub.status.busy":"2022-06-04T07:24:15.304243Z","iopub.status.idle":"2022-06-04T07:24:15.326771Z","shell.execute_reply":"2022-06-04T07:24:15.327392Z","shell.execute_reply.started":"2022-05-19T11:12:09.578375Z"},"papermill":{"duration":0.081707,"end_time":"2022-06-04T07:24:15.327566","exception":false,"start_time":"2022-06-04T07:24:15.245859","status":"completed"},"tags":[],"id":"f738388e","executionInfo":{"status":"ok","timestamp":1657613188861,"user_tz":-540,"elapsed":2,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["def apply_embedding_weights(target_layer, source_weights):\n","    \"\"\"Apply embedding weights to a target layer.\n","\n","    Args:\n","        target_layer: The target layer to which weights will\n","            be applied.\n","        source_weights: The source weights, which will be\n","            resized as necessary.\n","    \"\"\"\n","    expected_shape = target_layer.weights[0].shape\n","    if expected_shape == source_weights.shape:\n","        grid = source_weights\n","    elif expected_shape[1] == source_weights.shape[1] - 1:\n","        grid = source_weights[:, 1:]\n","    else:\n","        _, grid = source_weights[0, :1], source_weights[0, 1:]\n","        sin = int(np.sqrt(grid.shape[0]))\n","        sout = int(np.sqrt(expected_shape[1]))\n","        warnings.warn(\n","            \"Resizing position embeddings from \" f\"{sin} to {sout}\",\n","            UserWarning,\n","        )\n","        zoom = (sout / sin, sout / sin, 1)\n","        grid = scipy.ndimage.zoom(grid.reshape(sin, sin, -1), zoom, order=1).reshape(\n","            1, sout * sout, -1\n","        )\n","    target_layer.set_weights([grid])\n","\n","\n","def load_weights_numpy(model, params_path):\n","    \"\"\"Load weights saved using Flax as a numpy array.\n","\n","    Args:\n","        model: A Keras model to load the weights into.\n","        params_path: Filepath to a numpy archive.\n","    \"\"\"\n","    params_dict = np.load(\n","        params_path, allow_pickle=False\n","    )  # pylint: disable=unexpected-keyword-arg\n","    source_keys = list(params_dict.keys())\n","\n","    source_keys_used = []\n","    n_transformers = len(\n","        set(\n","            \"/\".join(k.split(\"/\")[:2])\n","            for k in source_keys\n","            if k.startswith(\"Transformer/encoderblock_\")\n","        )\n","    )\n","    n_transformers_out = sum(\n","        l.name.startswith(\"Transformer/encoderblock_\") for l in model.layers\n","    )\n","    assert n_transformers == n_transformers_out, (\n","        f\"Wrong number of transformers (\"\n","        f\"{n_transformers_out} in model vs. {n_transformers} in weights).\"\n","    )\n","\n","    matches = []\n","    for tidx in range(n_transformers):\n","        encoder = model.get_layer(f\"Transformer/encoderblock_{tidx}\")\n","        source_prefix = f\"Transformer/encoderblock_{tidx}\"\n","        matches.extend(\n","            [\n","                {\n","                    \"layer\": layer,\n","                    \"keys\": [\n","                        f\"{source_prefix}/{norm}/{name}\" for name in [\"scale\", \"bias\"]\n","                    ],\n","                }\n","                for norm, layer in [\n","                    (\"LayerNorm_0\", encoder.layernorm1),\n","                    (\"LayerNorm_2\", encoder.layernorm2),\n","                ]\n","            ]\n","            + [\n","                {\n","                    \"layer\": encoder.mlpblock.get_layer(\n","                        f\"{source_prefix}/Dense_{mlpdense}\"\n","                    ),\n","                    \"keys\": [\n","                        f\"{source_prefix}/MlpBlock_3/Dense_{mlpdense}/{name}\"\n","                        for name in [\"kernel\", \"bias\"]\n","                    ],\n","                }\n","                for mlpdense in [0, 1]\n","            ]\n","            + [\n","                {\n","                    \"layer\": layer,\n","                    \"keys\": [\n","                        f\"{source_prefix}/MultiHeadDotProductAttention_1/{attvar}/{name}\"\n","                        for name in [\"kernel\", \"bias\"]\n","                    ],\n","                    \"reshape\": True,\n","                }\n","                for attvar, layer in [\n","                    (\"query\", encoder.att.query_dense),\n","                    (\"key\", encoder.att.key_dense),\n","                    (\"value\", encoder.att.value_dense),\n","                    (\"out\", encoder.att.combine_heads),\n","                ]\n","            ]\n","        )\n","\n","    # Embedding kernel and bias\n","    matches.append(\n","        {\n","            \"layer\": model.get_layer(\"embedding\"),\n","            \"keys\": [f\"embedding/{name}\" for name in [\"kernel\", \"bias\"]],\n","        }\n","    )\n","\n","    matches.append(\n","        {\n","            \"layer\": model.get_layer(\"Transformer/encoder_norm\"),\n","            \"keys\": [f\"Transformer/encoder_norm/{name}\" for name in [\"scale\", \"bias\"]],\n","        }\n","    )\n","    apply_embedding_weights(\n","        target_layer=model.get_layer(\"Transformer/posembed_input\"),\n","        source_weights=params_dict[\"Transformer/posembed_input/pos_embedding\"],\n","    )\n","    source_keys_used.append(\"Transformer/posembed_input/pos_embedding\")\n","    for match in matches:\n","        source_keys_used.extend(match[\"keys\"])\n","        source_weights = [params_dict[k] for k in match[\"keys\"]]\n","        if match.get(\"reshape\", False):\n","            source_weights = [\n","                source.reshape(expected.shape)\n","                for source, expected in zip(\n","                    source_weights, match[\"layer\"].get_weights()\n","                )\n","            ]\n","        match[\"layer\"].set_weights(source_weights)"]},{"cell_type":"markdown","id":"a6692364","metadata":{"papermill":{"duration":0.056396,"end_time":"2022-06-04T07:24:15.439633","exception":false,"start_time":"2022-06-04T07:24:15.383237","status":"completed"},"tags":[],"id":"a6692364"},"source":["## Encoder\n","Key components of Encoder are,\n","* AddPositionEmbs\n","* MultiHeadSelfAttention\n","* TransformerBlock\n","* ResNet_Embeddings"]},{"cell_type":"code","execution_count":23,"id":"0399694e","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:15.585882Z","iopub.status.busy":"2022-06-04T07:24:15.560951Z","iopub.status.idle":"2022-06-04T07:24:15.588877Z","shell.execute_reply":"2022-06-04T07:24:15.588301Z","shell.execute_reply.started":"2022-05-19T11:12:09.60406Z"},"papermill":{"duration":0.094039,"end_time":"2022-06-04T07:24:15.589032","exception":false,"start_time":"2022-06-04T07:24:15.494993","status":"completed"},"tags":[],"id":"0399694e","executionInfo":{"status":"ok","timestamp":1657613189887,"user_tz":-540,"elapsed":569,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["class AddPositionEmbs(tfkl.Layer):\n","    \"\"\"Adds (optionally learned) positional embeddings to the inputs.\"\"\"\n","\n","    def __init__(self, trainable=True, **kwargs):\n","        super().__init__(trainable=trainable, **kwargs)\n","        self.trainable = trainable\n","\n","    def build(self, input_shape):\n","        assert (\n","            len(input_shape) == 3\n","        ), f\"Number of dimensions should be 3, got {len(input_shape)}\"\n","        self.pe = tf.Variable(\n","            name=\"pos_embedding\",\n","            initial_value=tf.random_normal_initializer(stddev=0.06)(\n","                shape=(1, input_shape[1], input_shape[2])\n","            ),\n","            dtype=\"float32\",\n","            trainable=self.trainable,\n","        )\n","\n","    def call(self, inputs):\n","        return inputs + tf.cast(self.pe, dtype=inputs.dtype)\n","\n","\n","class MultiHeadSelfAttention(tfkl.Layer):\n","    def __init__(self, *args, trainable=True, n_heads, **kwargs):\n","        super().__init__(trainable=trainable, *args, **kwargs)\n","        self.n_heads = n_heads\n","\n","    def build(self, input_shape):\n","        hidden_size = input_shape[-1]\n","        n_heads = self.n_heads\n","        if hidden_size % n_heads != 0:\n","            raise ValueError(\n","                f\"embedding dimension = {hidden_size} should be divisible by number of heads = {n_heads}\"\n","            )\n","        self.hidden_size = hidden_size\n","        self.projection_dim = hidden_size // n_heads\n","        self.query_dense = tfkl.Dense(hidden_size, name=\"query\")\n","        self.key_dense = tfkl.Dense(hidden_size, name=\"key\")\n","        self.value_dense = tfkl.Dense(hidden_size, name=\"value\")\n","        self.combine_heads = tfkl.Dense(hidden_size, name=\"out\")\n","\n","    # pylint: disable=no-self-use\n","    def attention(self, query, key, value):\n","        score = tf.matmul(query, key, transpose_b=True)\n","        dim_key = tf.cast(tf.shape(key)[-1], score.dtype)\n","        scaled_score = score / tf.math.sqrt(dim_key)\n","        weights = tf.nn.softmax(scaled_score, axis=-1)\n","        output = tf.matmul(weights, value)\n","        return output, weights\n","\n","    def separate_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.projection_dim))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, inputs):\n","        batch_size = tf.shape(inputs)[0]\n","        query = self.query_dense(inputs)\n","        key = self.key_dense(inputs)\n","        value = self.value_dense(inputs)\n","        query = self.separate_heads(query, batch_size)\n","        key = self.separate_heads(key, batch_size)\n","        value = self.separate_heads(value, batch_size)\n","\n","        attention, weights = self.attention(query, key, value)\n","        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n","        concat_attention = tf.reshape(attention, (batch_size, -1, self.hidden_size))\n","        output = self.combine_heads(concat_attention)\n","        return output, weights\n","\n","\n","class TransformerBlock(tfkl.Layer):\n","    \"\"\"Implements a Transformer block.\"\"\"\n","\n","    def __init__(self, *args, n_heads, mlp_dim, dropout, trainable=True, **kwargs):\n","        super().__init__(*args, trainable=trainable, **kwargs)\n","        self.n_heads = n_heads\n","        self.mlp_dim = mlp_dim\n","        self.dropout = dropout\n","\n","    def build(self, input_shape):\n","        self.att = MultiHeadSelfAttention(\n","            n_heads=self.n_heads,\n","            name=\"MultiHeadDotProductAttention_1\",\n","        )\n","        self.mlpblock = tfk.Sequential(\n","            [\n","                tfkl.Dense(\n","                    self.mlp_dim, activation=\"linear\", name=f\"{self.name}/Dense_0\"\n","                ),\n","                tfkl.Lambda(lambda x: tfk.activations.gelu(x, approximate=False))\n","                if hasattr(tfk.activations, \"gelu\")\n","                else tfkl.Lambda(lambda x: tfa.activations.gelu(x, approximate=False)),\n","                tfkl.Dropout(self.dropout),\n","                tfkl.Dense(input_shape[-1], name=f\"{self.name}/Dense_1\"),\n","                tfkl.Dropout(self.dropout),\n","            ],\n","            name=\"MlpBlock_3\",\n","        )\n","        self.layernorm1 = tfkl.LayerNormalization(epsilon=1e-6, name=\"LayerNorm_0\")\n","        self.layernorm2 = tfkl.LayerNormalization(epsilon=1e-6, name=\"LayerNorm_2\")\n","        self.dropout = tfkl.Dropout(self.dropout)\n","\n","    def call(self, inputs, training):\n","        x = self.layernorm1(inputs)\n","        x, weights = self.att(x)\n","        x = self.dropout(x, training=training)\n","        x = x + inputs\n","        y = self.layernorm2(x)\n","        y = self.mlpblock(y)\n","        return x + y, weights\n","\n","\n","def resnet_embeddings(x, image_size=224, n_skip=3):\n","    \"\"\"Get resnet embeddings for Decoder\"\"\"\n","    resnet50v2 = tfk.applications.ResNet50V2(\n","        weights=\"imagenet\", include_top=False, input_shape=(image_size, image_size, 3)\n","    )\n","    _ = resnet50v2(x)\n","    layers = [\"conv3_block4_preact_relu\", \"conv2_block3_preact_relu\", \"conv1_conv\"]\n","    features = []\n","    if n_skip > 0:\n","        for l in layers:\n","            features.append(resnet50v2.get_layer(l).output)\n","    return resnet50v2, features"]},{"cell_type":"markdown","id":"bf7efab8","metadata":{"papermill":{"duration":0.055009,"end_time":"2022-06-04T07:24:15.700885","exception":false,"start_time":"2022-06-04T07:24:15.645876","status":"completed"},"tags":[],"id":"bf7efab8"},"source":["## Decoder\n","Key components of Decoders are,\n","* SegmentationHead\n","* Conv2DReLu\n","* DecoderBlock\n","* DecoderCup"]},{"cell_type":"code","execution_count":24,"id":"a9115578","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:15.816971Z","iopub.status.busy":"2022-06-04T07:24:15.816265Z","iopub.status.idle":"2022-06-04T07:24:15.838093Z","shell.execute_reply":"2022-06-04T07:24:15.838607Z","shell.execute_reply.started":"2022-05-19T11:12:09.638862Z"},"papermill":{"duration":0.082603,"end_time":"2022-06-04T07:24:15.838778","exception":false,"start_time":"2022-06-04T07:24:15.756175","status":"completed"},"tags":[],"id":"a9115578","executionInfo":{"status":"ok","timestamp":1657613189887,"user_tz":-540,"elapsed":4,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["L2_WEIGHT_DECAY = 1e-4\n","\n","\n","class SegmentationHead(tfkl.Layer):\n","    def __init__(\n","        self,\n","        name=\"seg_head\",\n","        num_classes=9,\n","        kernel_size=1,\n","        final_act=\"sigmoid\",\n","        **kwargs\n","    ):\n","        super(SegmentationHead, self).__init__(name=name, **kwargs)\n","        self.num_classes = num_classes\n","        self.kernel_size = kernel_size\n","        self.final_act = final_act\n","\n","    def build(self, input_shape):\n","        self.conv = tfkl.Conv2D(\n","            filters=self.num_classes,\n","            kernel_size=self.kernel_size,\n","            padding=\"same\",\n","            kernel_regularizer=tfk.regularizers.L2(L2_WEIGHT_DECAY),\n","            kernel_initializer=tfk.initializers.LecunNormal(),\n","        )\n","        self.act = tfkl.Activation(self.final_act)\n","\n","    def call(self, inputs):\n","        x = self.conv(inputs)\n","        x = self.act(x)\n","        return x\n","\n","\n","class Conv2DReLu(tfkl.Layer):\n","    def __init__(self, filters, kernel_size, padding=\"same\", strides=1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.filters = filters\n","        self.kernel_size = kernel_size\n","        self.padding = padding\n","        self.strides = strides\n","\n","    def build(self, input_shape):\n","        self.conv = tfkl.Conv2D(\n","            filters=self.filters,\n","            kernel_size=self.kernel_size,\n","            strides=self.strides,\n","            padding=self.padding,\n","            use_bias=False,\n","            kernel_regularizer=tfk.regularizers.L2(L2_WEIGHT_DECAY),\n","            kernel_initializer=\"lecun_normal\",\n","        )\n","\n","        self.bn = tfkl.BatchNormalization(momentum=0.9, epsilon=1e-5)\n","\n","    def call(self, inputs):\n","        x = self.conv(inputs)\n","        x = self.bn(x)\n","        x = tf.nn.relu(x)\n","        return x\n","\n","\n","class DecoderBlock(tfkl.Layer):\n","    def __init__(self, filters, **kwargs):\n","        super().__init__(**kwargs)\n","        self.filters = filters\n","\n","    def build(self, input_shape):\n","        self.conv1 = Conv2DReLu(filters=self.filters, kernel_size=3)\n","        self.conv2 = Conv2DReLu(filters=self.filters, kernel_size=3)\n","        self.upsampling = tfkl.UpSampling2D(size=2, interpolation=\"bilinear\")\n","\n","    def call(self, inputs, skip=None):\n","        x = self.upsampling(inputs)\n","        if skip is not None:\n","            x = tf.concat([x, skip], axis=-1)\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        return x\n","\n","\n","class DecoderCup(tfkl.Layer):\n","    def __init__(self, decoder_channels, n_skip=3, **kwargs):\n","        super().__init__(**kwargs)\n","        self.decoder_channels = decoder_channels\n","        self.n_skip = n_skip\n","\n","    def build(self, input_shape):\n","        self.conv_more = Conv2DReLu(filters=512, kernel_size=3)\n","        self.blocks = [DecoderBlock(filters=out_ch) for out_ch in self.decoder_channels]\n","\n","    def call(self, hidden_states, features):\n","        x = self.conv_more(hidden_states)\n","        for i, decoder_block in enumerate(self.blocks):\n","            if features is not None:\n","                skip = features[i] if (i < self.n_skip) else None\n","            else:\n","                skip = None\n","            x = decoder_block(x, skip=skip)\n","        return x\n"]},{"cell_type":"markdown","id":"cb1028c1","metadata":{"papermill":{"duration":0.055981,"end_time":"2022-06-04T07:24:15.950844","exception":false,"start_time":"2022-06-04T07:24:15.894863","status":"completed"},"tags":[],"id":"cb1028c1"},"source":["## Model\n","* Merge Encoder & Decoder part of TransUNet Model.\n","* You can also ditch so many lines of code above for **TransUNet** model and load model directly using simple two lines of code,\n","```py\n","from transunet import TransUNet\n","model = TransUNet(image_size=224, pretrain=True)\n","```"]},{"cell_type":"code","execution_count":25,"id":"5fbc739f","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:16.065836Z","iopub.status.busy":"2022-06-04T07:24:16.065131Z","iopub.status.idle":"2022-06-04T07:24:16.082029Z","shell.execute_reply":"2022-06-04T07:24:16.082556Z","shell.execute_reply.started":"2022-05-19T11:12:09.661989Z"},"papermill":{"duration":0.076308,"end_time":"2022-06-04T07:24:16.082731","exception":false,"start_time":"2022-06-04T07:24:16.006423","status":"completed"},"tags":[],"id":"5fbc739f","executionInfo":{"status":"ok","timestamp":1657613189887,"user_tz":-540,"elapsed":4,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["MODELS_URL = \"https://storage.googleapis.com/vit_models/imagenet21k/\"\n","\n","\n","def load_pretrained(model, fname=\"R50+ViT-B_16.npz\"):\n","    \"\"\"Load model weights for a known configuration.\"\"\"\n","    origin = MODELS_URL + fname\n","    local_filepath = tf.keras.utils.get_file(fname, origin, cache_subdir=\"weights\")\n","    load_weights_numpy(model, local_filepath)\n","\n","\n","def TransUNet(\n","    image_size=224,\n","    patch_size=16,\n","    hybrid=True,\n","    grid=(14, 14),\n","    resnet_n_layers=(3, 4, 9),\n","    hidden_size=768,\n","    n_layers=12,\n","    n_heads=12,\n","    mlp_dim=3072,\n","    dropout=0.1,\n","    decoder_channels=[256, 128, 64, 16],\n","    n_skip=3,\n","    num_classes=3,\n","    final_act=\"sigmoid\",\n","    pretrain=True,\n","    freeze_enc_cnn=True,\n","    name=\"TransUNet\",\n","):\n","    # Tranformer Encoder\n","    assert image_size % patch_size == 0, \"image_size must be a multiple of patch_size\"\n","    x = tf.keras.layers.Input(shape=(image_size, image_size, 3))\n","\n","    #  CNN + Transformer\n","    if hybrid:\n","        grid_size = grid\n","        patch_size = image_size // 16 // grid_size[0]\n","        if patch_size == 0:\n","            patch_size = 1\n","        resnet50v2, features = resnet_embeddings(\n","            x, image_size=image_size, n_skip=n_skip\n","        )\n","        if freeze_enc_cnn:\n","            resnet50v2.trainable = False\n","        y = resnet50v2.get_layer(\"conv4_block6_preact_relu\").output\n","        x = resnet50v2.input\n","    else:\n","        y = x\n","        features = None\n","\n","    y = tfkl.Conv2D(\n","        filters=hidden_size,\n","        kernel_size=patch_size,\n","        strides=patch_size,\n","        padding=\"valid\",\n","        name=\"embedding\",\n","        trainable=not freeze_enc_cnn,\n","    )(y)\n","    y = tfkl.Reshape((y.shape[1] * y.shape[2], hidden_size))(y)\n","    y = AddPositionEmbs(name=\"Transformer/posembed_input\", trainable=True)(y)\n","\n","    y = tfkl.Dropout(0.1)(y)\n","\n","    # Transformer/Encoder\n","    for n in range(n_layers):\n","        y, _ = TransformerBlock(\n","            n_heads=n_heads,\n","            mlp_dim=mlp_dim,\n","            dropout=dropout,\n","            name=f\"Transformer/encoderblock_{n}\",\n","            trainable=True,\n","        )(y)\n","    y = tfkl.LayerNormalization(epsilon=1e-6, name=\"Transformer/encoder_norm\")(y)\n","\n","    n_patch_sqrt = int(math.sqrt(y.shape[1]))\n","\n","    y = tfkl.Reshape(target_shape=[n_patch_sqrt, n_patch_sqrt, hidden_size])(y)\n","\n","    # Decoder\n","    if len(decoder_channels):\n","        y = DecoderCup(decoder_channels=decoder_channels, n_skip=n_skip)(y, features)\n","\n","    # Segmentation Head\n","    y = SegmentationHead(num_classes=num_classes, final_act=final_act)(y)\n","\n","    # Build Model\n","    model = tfk.models.Model(inputs=x, outputs=y, name=name)\n","\n","    # Load Pretrain Weights\n","    if pretrain:\n","        load_pretrained(model)\n","\n","    return model"]},{"cell_type":"markdown","id":"070f287d","metadata":{"papermill":{"duration":0.055317,"end_time":"2022-06-04T07:24:16.193591","exception":false,"start_time":"2022-06-04T07:24:16.138274","status":"completed"},"tags":[],"id":"070f287d"},"source":["## Build Model\n","* Build complete model.\n","* Select Loss, LR_Scheduling, Metrics and so on.\n","* Compile model for training."]},{"cell_type":"code","execution_count":26,"id":"45437d1d","metadata":{"execution":{"iopub.execute_input":"2022-06-04T07:24:16.316593Z","iopub.status.busy":"2022-06-04T07:24:16.310367Z","iopub.status.idle":"2022-06-04T07:24:16.319673Z","shell.execute_reply":"2022-06-04T07:24:16.319175Z","shell.execute_reply.started":"2022-05-19T11:12:09.683401Z"},"papermill":{"duration":0.069861,"end_time":"2022-06-04T07:24:16.319828","exception":false,"start_time":"2022-06-04T07:24:16.249967","status":"completed"},"tags":[],"id":"45437d1d","executionInfo":{"status":"ok","timestamp":1657613189887,"user_tz":-540,"elapsed":3,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[],"source":["def get_model(name=CFG.model_name, loss=CFG.loss, backbone=CFG.backbone):\n","    model = TransUNet(image_size=CFG.img_size[0], freeze_enc_cnn=False, pretrain=True)\n","\n","    lr = CFG.lr\n","    if CFG.optimizer == \"Adam\":\n","        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n","    elif CFG.optimizer == \"AdamW\":\n","        opt = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=lr)\n","    elif CFG.optimizer == \"RectifiedAdam\":\n","        opt = tfa.optimizers.RectifiedAdam(learning_rate=lr)\n","    else:\n","        raise ValueError(\"Wrong Optimzer Name\")\n","\n","    model.compile(\n","        optimizer=opt,\n","        loss=loss,\n","        steps_per_execution=CFG.steps_per_execution, # to reduce idle time\n","        metrics=[\n","            dice_coef,\n","            \"precision\",\n","            \"recall\",\n","        ],\n","    )\n","    return model"]},{"cell_type":"code","execution_count":27,"id":"5aa8c516","metadata":{"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2022-06-04T07:24:16.436372Z","iopub.status.busy":"2022-06-04T07:24:16.435497Z","iopub.status.idle":"2022-06-04T07:24:31.382451Z","shell.execute_reply":"2022-06-04T07:24:31.383005Z","shell.execute_reply.started":"2022-05-19T11:12:09.698244Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":15.007689,"end_time":"2022-06-04T07:24:31.383220","exception":false,"start_time":"2022-06-04T07:24:16.375531","status":"completed"},"tags":[],"id":"5aa8c516","outputId":"17feb7ef-e1a4-4aab-86e8-493b5ba17df6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657613216969,"user_tz":-540,"elapsed":27085,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94674944/94668760 [==============================] - 1s 0us/step\n","94683136/94668760 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/vit_models/imagenet21k/R50+ViT-B_16.npz\n","461217792/461217452 [==============================] - 11s 0us/step\n","461225984/461217452 [==============================] - 11s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Resizing position embeddings from 14 to 8\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"TransUNet\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)      (None, 134, 134, 3)  0           ['input_2[0][0]']                \n","                                                                                                  \n"," conv1_conv (Conv2D)            (None, 64, 64, 64)   9472        ['conv1_pad[0][0]']              \n","                                                                                                  \n"," pool1_pad (ZeroPadding2D)      (None, 66, 66, 64)   0           ['conv1_conv[0][0]']             \n","                                                                                                  \n"," pool1_pool (MaxPooling2D)      (None, 32, 32, 64)   0           ['pool1_pad[0][0]']              \n","                                                                                                  \n"," conv2_block1_preact_bn (BatchN  (None, 32, 32, 64)  256         ['pool1_pool[0][0]']             \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2_block1_preact_relu (Acti  (None, 32, 32, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv2_block1_1_conv (Conv2D)   (None, 32, 32, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv2_block1_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_2_pad (ZeroPaddin  (None, 34, 34, 64)  0           ['conv2_block1_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2_block1_2_conv (Conv2D)   (None, 32, 32, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n","                                                                                                  \n"," conv2_block1_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_0_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv2_block1_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block1_out (Add)         (None, 32, 32, 256)  0           ['conv2_block1_0_conv[0][0]',    \n","                                                                  'conv2_block1_3_conv[0][0]']    \n","                                                                                                  \n"," conv2_block2_preact_bn (BatchN  (None, 32, 32, 256)  1024       ['conv2_block1_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2_block2_preact_relu (Acti  (None, 32, 32, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv2_block2_1_conv (Conv2D)   (None, 32, 32, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv2_block2_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block2_2_pad (ZeroPaddin  (None, 34, 34, 64)  0           ['conv2_block2_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2_block2_2_conv (Conv2D)   (None, 32, 32, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n","                                                                                                  \n"," conv2_block2_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block2_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block2_out (Add)         (None, 32, 32, 256)  0           ['conv2_block1_out[0][0]',       \n","                                                                  'conv2_block2_3_conv[0][0]']    \n","                                                                                                  \n"," conv2_block3_preact_bn (BatchN  (None, 32, 32, 256)  1024       ['conv2_block2_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2_block3_preact_relu (Acti  (None, 32, 32, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv2_block3_1_conv (Conv2D)   (None, 32, 32, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv2_block3_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block3_2_pad (ZeroPaddin  (None, 34, 34, 64)  0           ['conv2_block3_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2_block3_2_conv (Conv2D)   (None, 16, 16, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n","                                                                                                  \n"," conv2_block3_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 16, 16, 256)  0           ['conv2_block2_out[0][0]']       \n","                                                                                                  \n"," conv2_block3_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block3_out (Add)         (None, 16, 16, 256)  0           ['max_pooling2d[0][0]',          \n","                                                                  'conv2_block3_3_conv[0][0]']    \n","                                                                                                  \n"," conv3_block1_preact_bn (BatchN  (None, 16, 16, 256)  1024       ['conv2_block3_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv3_block1_preact_relu (Acti  (None, 16, 16, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv3_block1_1_conv (Conv2D)   (None, 16, 16, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv3_block1_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block1_2_pad (ZeroPaddin  (None, 18, 18, 128)  0          ['conv3_block1_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv3_block1_2_conv (Conv2D)   (None, 16, 16, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n","                                                                                                  \n"," conv3_block1_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block1_0_conv (Conv2D)   (None, 16, 16, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv3_block1_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block1_out (Add)         (None, 16, 16, 512)  0           ['conv3_block1_0_conv[0][0]',    \n","                                                                  'conv3_block1_3_conv[0][0]']    \n","                                                                                                  \n"," conv3_block2_preact_bn (BatchN  (None, 16, 16, 512)  2048       ['conv3_block1_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv3_block2_preact_relu (Acti  (None, 16, 16, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv3_block2_1_conv (Conv2D)   (None, 16, 16, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv3_block2_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block2_2_pad (ZeroPaddin  (None, 18, 18, 128)  0          ['conv3_block2_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv3_block2_2_conv (Conv2D)   (None, 16, 16, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n","                                                                                                  \n"," conv3_block2_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block2_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block2_out (Add)         (None, 16, 16, 512)  0           ['conv3_block1_out[0][0]',       \n","                                                                  'conv3_block2_3_conv[0][0]']    \n","                                                                                                  \n"," conv3_block3_preact_bn (BatchN  (None, 16, 16, 512)  2048       ['conv3_block2_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv3_block3_preact_relu (Acti  (None, 16, 16, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv3_block3_1_conv (Conv2D)   (None, 16, 16, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv3_block3_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block3_2_pad (ZeroPaddin  (None, 18, 18, 128)  0          ['conv3_block3_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv3_block3_2_conv (Conv2D)   (None, 16, 16, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n","                                                                                                  \n"," conv3_block3_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block3_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block3_out (Add)         (None, 16, 16, 512)  0           ['conv3_block2_out[0][0]',       \n","                                                                  'conv3_block3_3_conv[0][0]']    \n","                                                                                                  \n"," conv3_block4_preact_bn (BatchN  (None, 16, 16, 512)  2048       ['conv3_block3_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv3_block4_preact_relu (Acti  (None, 16, 16, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv3_block4_1_conv (Conv2D)   (None, 16, 16, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv3_block4_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block4_2_pad (ZeroPaddin  (None, 18, 18, 128)  0          ['conv3_block4_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv3_block4_2_conv (Conv2D)   (None, 8, 8, 128)    147456      ['conv3_block4_2_pad[0][0]']     \n","                                                                                                  \n"," conv3_block4_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 512)   0           ['conv3_block3_out[0][0]']       \n","                                                                                                  \n"," conv3_block4_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block4_out (Add)         (None, 8, 8, 512)    0           ['max_pooling2d_1[0][0]',        \n","                                                                  'conv3_block4_3_conv[0][0]']    \n","                                                                                                  \n"," conv4_block1_preact_bn (BatchN  (None, 8, 8, 512)   2048        ['conv3_block4_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv4_block1_preact_relu (Acti  (None, 8, 8, 512)   0           ['conv4_block1_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv4_block1_1_conv (Conv2D)   (None, 8, 8, 256)    131072      ['conv4_block1_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv4_block1_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block1_2_pad (ZeroPaddin  (None, 10, 10, 256)  0          ['conv4_block1_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv4_block1_2_conv (Conv2D)   (None, 8, 8, 256)    589824      ['conv4_block1_2_pad[0][0]']     \n","                                                                                                  \n"," conv4_block1_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block1_0_conv (Conv2D)   (None, 8, 8, 1024)   525312      ['conv4_block1_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv4_block1_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block1_out (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_0_conv[0][0]',    \n","                                                                  'conv4_block1_3_conv[0][0]']    \n","                                                                                                  \n"," conv4_block2_preact_bn (BatchN  (None, 8, 8, 1024)  4096        ['conv4_block1_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv4_block2_preact_relu (Acti  (None, 8, 8, 1024)  0           ['conv4_block2_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv4_block2_1_conv (Conv2D)   (None, 8, 8, 256)    262144      ['conv4_block2_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv4_block2_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block2_2_pad (ZeroPaddin  (None, 10, 10, 256)  0          ['conv4_block2_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv4_block2_2_conv (Conv2D)   (None, 8, 8, 256)    589824      ['conv4_block2_2_pad[0][0]']     \n","                                                                                                  \n"," conv4_block2_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block2_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block2_out (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_out[0][0]',       \n","                                                                  'conv4_block2_3_conv[0][0]']    \n","                                                                                                  \n"," conv4_block3_preact_bn (BatchN  (None, 8, 8, 1024)  4096        ['conv4_block2_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv4_block3_preact_relu (Acti  (None, 8, 8, 1024)  0           ['conv4_block3_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv4_block3_1_conv (Conv2D)   (None, 8, 8, 256)    262144      ['conv4_block3_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv4_block3_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block3_2_pad (ZeroPaddin  (None, 10, 10, 256)  0          ['conv4_block3_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv4_block3_2_conv (Conv2D)   (None, 8, 8, 256)    589824      ['conv4_block3_2_pad[0][0]']     \n","                                                                                                  \n"," conv4_block3_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block3_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block3_out (Add)         (None, 8, 8, 1024)   0           ['conv4_block2_out[0][0]',       \n","                                                                  'conv4_block3_3_conv[0][0]']    \n","                                                                                                  \n"," conv4_block4_preact_bn (BatchN  (None, 8, 8, 1024)  4096        ['conv4_block3_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv4_block4_preact_relu (Acti  (None, 8, 8, 1024)  0           ['conv4_block4_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv4_block4_1_conv (Conv2D)   (None, 8, 8, 256)    262144      ['conv4_block4_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv4_block4_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block4_2_pad (ZeroPaddin  (None, 10, 10, 256)  0          ['conv4_block4_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv4_block4_2_conv (Conv2D)   (None, 8, 8, 256)    589824      ['conv4_block4_2_pad[0][0]']     \n","                                                                                                  \n"," conv4_block4_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block4_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block4_out (Add)         (None, 8, 8, 1024)   0           ['conv4_block3_out[0][0]',       \n","                                                                  'conv4_block4_3_conv[0][0]']    \n","                                                                                                  \n"," conv4_block5_preact_bn (BatchN  (None, 8, 8, 1024)  4096        ['conv4_block4_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv4_block5_preact_relu (Acti  (None, 8, 8, 1024)  0           ['conv4_block5_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," conv4_block5_1_conv (Conv2D)   (None, 8, 8, 256)    262144      ['conv4_block5_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," conv4_block5_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block5_2_pad (ZeroPaddin  (None, 10, 10, 256)  0          ['conv4_block5_1_relu[0][0]']    \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv4_block5_2_conv (Conv2D)   (None, 8, 8, 256)    589824      ['conv4_block5_2_pad[0][0]']     \n","                                                                                                  \n"," conv4_block5_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block5_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block5_out (Add)         (None, 8, 8, 1024)   0           ['conv4_block4_out[0][0]',       \n","                                                                  'conv4_block5_3_conv[0][0]']    \n","                                                                                                  \n"," conv4_block6_preact_bn (BatchN  (None, 8, 8, 1024)  4096        ['conv4_block5_out[0][0]']       \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv4_block6_preact_relu (Acti  (None, 8, 8, 1024)  0           ['conv4_block6_preact_bn[0][0]'] \n"," vation)                                                                                          \n","                                                                                                  \n"," embedding (Conv2D)             (None, 8, 8, 768)    787200      ['conv4_block6_preact_relu[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," reshape (Reshape)              (None, 64, 768)      0           ['embedding[0][0]']              \n","                                                                                                  \n"," Transformer/posembed_input (Ad  (None, 64, 768)     49152       ['reshape[0][0]']                \n"," dPositionEmbs)                                                                                   \n","                                                                                                  \n"," dropout (Dropout)              (None, 64, 768)      0           ['Transformer/posembed_input[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," Transformer/encoderblock_0 (Tr  ((None, 64, 768),   7087872     ['dropout[0][0]']                \n"," ansformerBlock)                 (None, 12, None, N                                               \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_1 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_0[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_2 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_1[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_3 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_2[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_4 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_3[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_5 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_4[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_6 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_5[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_7 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_6[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_8 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_7[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_9 (Tr  ((None, 64, 768),   7087872     ['Transformer/encoderblock_8[0][0\n"," ansformerBlock)                 (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_10 (T  ((None, 64, 768),   7087872     ['Transformer/encoderblock_9[0][0\n"," ransformerBlock)                (None, 12, None, N              ]']                              \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoderblock_11 (T  ((None, 64, 768),   7087872     ['Transformer/encoderblock_10[0][\n"," ransformerBlock)                (None, 12, None, N              0]']                             \n","                                one))                                                             \n","                                                                                                  \n"," Transformer/encoder_norm (Laye  (None, 64, 768)     1536        ['Transformer/encoderblock_11[0][\n"," rNormalization)                                                 0]']                             \n","                                                                                                  \n"," reshape_1 (Reshape)            (None, 8, 8, 768)    0           ['Transformer/encoder_norm[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," decoder_cup (DecoderCup)       (None, 128, 128, 16  7390080     ['reshape_1[0][0]',              \n","                                )                                 'conv3_block4_preact_relu[0][0]'\n","                                                                 , 'conv2_block3_preact_relu[0][0]\n","                                                                 ',                               \n","                                                                  'conv1_conv[0][0]']             \n","                                                                                                  \n"," seg_head (SegmentationHead)    (None, 128, 128, 3)  51          ['decoder_cup[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 100,738,739\n","Trainable params: 100,711,923\n","Non-trainable params: 26,816\n","__________________________________________________________________________________________________\n"]}],"source":["model = get_model()\n","model.summary()"]},{"cell_type":"markdown","id":"15325ba9","metadata":{"papermill":{"duration":0.087951,"end_time":"2022-06-04T07:24:32.957890","exception":false,"start_time":"2022-06-04T07:24:32.869939","status":"completed"},"tags":[],"id":"15325ba9"},"source":["# 14. Training ðŸš…\n","Our model will be trained for the number of `FOLDS` and `EPOCHS` you chose in the configuration above. Each fold the model with hightest validation `Dice Score` will be saved and used to predict OOF and test. "]},{"cell_type":"code","source":["TRAIN_FILENAMES = [ALL_FILENAMES[i] for i in train_idx]"],"metadata":{"id":"H5vB0EhTePEq","executionInfo":{"status":"ok","timestamp":1657613668453,"user_tz":-540,"elapsed":433,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"id":"H5vB0EhTePEq","execution_count":32,"outputs":[]},{"cell_type":"code","source":["len(TRAIN_FILENAMES)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBALe26PeVon","executionInfo":{"status":"ok","timestamp":1657613692180,"user_tz":-540,"elapsed":2,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"3139c2c0-5c9e-4af0-f2dd-5d4f62b4a2a3"},"id":"vBALe26PeVon","execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30796"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["VALID_FILENAMES = [ALL_FILENAMES[i] for i in valid_idx]\n","len(VALID_FILENAMES)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OrbHREzbefds","executionInfo":{"status":"ok","timestamp":1657613727692,"user_tz":-540,"elapsed":3,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}},"outputId":"a191b705-88ce-4a35-c89c-6851fe934439"},"id":"OrbHREzbefds","execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7700"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":36,"id":"71f0d2d8","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.execute_input":"2022-06-04T07:24:33.154484Z","iopub.status.busy":"2022-06-04T07:24:33.153598Z","iopub.status.idle":"2022-06-04T08:13:35.763024Z","shell.execute_reply":"2022-06-04T08:13:35.763632Z"},"papermill":{"duration":2942.715575,"end_time":"2022-06-04T08:13:35.763887","exception":false,"start_time":"2022-06-04T07:24:33.048312","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"71f0d2d8","outputId":"8cbfb9bb-c3b6-438a-cc28-d7cece4e6fbe","executionInfo":{"status":"error","timestamp":1657616613739,"user_tz":-540,"elapsed":614,"user":{"displayName":"ê³¨ë“œí‚¤ìœ„","userId":"02087811486056442719"}}},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-b0f644545828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Count train and valid samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mNUM_TRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_data_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FILENAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mNUM_VALID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_data_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALID_FILENAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-6dfa85f6f9b9>\u001b[0m in \u001b[0;36mcount_data_items\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_data_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"-([0-9]*)\\.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-6dfa85f6f9b9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_data_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"-([0-9]*)\\.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"]}],"source":["M = {}\n","# Which Metrics to store\n","metrics = [\n","    \"loss\",\n","    \"dice_coef\",\n","    \"precision\",\n","    \"recall\",\n","]\n","# Intialize Metrics\n","for fm in metrics:\n","    M[\"val_\" + fm] = []\n","\n","ALL_FILENAMES = sorted(ALL_FILENAMES)\n","\n","# Split tfrecord using KFold\n","kf = KFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed) # kfold between trrecord files\n","for fold, (train_idx, valid_idx) in enumerate(kf.split(ALL_FILENAMES)):\n","    # If fold is not in selected folds then avoid that fold\n","    if fold not in CFG.selected_folds:\n","        continue\n","        \n","    # Initialize wandb Run\n","\n","    # Train and validation files\n","    TRAIN_FILENAMES = [ALL_FILENAMES[i] for i in train_idx]\n","    VALID_FILENAMES = [ALL_FILENAMES[i] for i in valid_idx]\n","    \n","    # Take Only 10 Files if run in Debug Mode\n","    if CFG.debug:\n","        TRAIN_FILENAMES = TRAIN_FILENAMES[:10]\n","        VALID_FILENAMES = VALID_FILENAMES[:10]\n","\n","    # Shuffle train files\n","    random.shuffle(TRAIN_FILENAMES)\n","\n","    # Count train and valid samples\n","    NUM_TRAIN = count_data_items(TRAIN_FILENAMES)\n","    NUM_VALID = count_data_items(VALID_FILENAMES)\n","\n","    # Compute batch size & steps_per_epoch\n","    BATCH_SIZE = CFG.batch_size * REPLICAS\n","    STEPS_PER_EPOCH = NUM_TRAIN // BATCH_SIZE\n","\n","    print(\"#\" * 65)\n","    print(\"#### FOLD:\", fold)\n","    print(\n","        \"#### IMAGE_SIZE: (%i, %i) | BATCH_SIZE: %i | EPOCHS: %i\"\n","        % (CFG.img_size[0], CFG.img_size[1], BATCH_SIZE, CFG.epochs)\n","    )\n","    print(\n","        \"#### MODEL: %s | BACKBONE: %s | LOSS: %s\"\n","        % (CFG.model_name, CFG.backbone, CFG.loss)\n","    )\n","    print(\"#### NUM_TRAIN: {:,} | NUM_VALID: {:,}\".format(NUM_TRAIN, NUM_VALID))\n","    print(\"#\" * 65)\n","\n","    # Build model in device\n","    K.clear_session()\n","    with strategy.scope():\n","        model = get_model(name=CFG.model_name, backbone=CFG.backbone, loss=CFG.loss)\n","\n","    # Callbacks\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","        \"/kaggle/working/fold-%i.h5\" % fold,\n","        verbose=CFG.verbose,\n","        monitor=\"val_dice_coef\",\n","        mode=\"max\",\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","    callbacks = [checkpoint, get_lr_callback()]\n","\n","\n","    # Create train & valid dataset\n","    train_ds = get_dataset(\n","        TRAIN_FILENAMES,\n","        augment=CFG.augment,\n","        batch_size=BATCH_SIZE,\n","        cache=False,\n","        drop_remainder=False,\n","    )\n","    valid_ds = get_dataset(\n","        VALID_FILENAMES,\n","        shuffle=False,\n","        augment=False,\n","        repeat=False,\n","        batch_size=BATCH_SIZE,\n","        cache=False,\n","        drop_remainder=False,\n","    )\n","\n","    # Train model\n","    history = model.fit(\n","        train_ds,\n","        epochs=CFG.epochs if not CFG.debug else 2,\n","        steps_per_epoch=STEPS_PER_EPOCH,\n","        callbacks=callbacks,\n","        validation_data=valid_ds,\n","        #         validation_steps = NUM_VALID/BATCH_SIZE,\n","        verbose=CFG.verbose,\n","    )\n","\n","    # Convert dict history to df history\n","    history = pd.DataFrame(history.history)\n","\n","    # Load best weights\n","    model.load_weights(\"/kaggle/working/fold-%i.h5\" % fold)\n","\n","    # Compute & save best valid result\n","    print(\"\\nValid Result:\")\n","    m = model.evaluate(\n","        get_dataset(\n","            VALID_FILENAMES,\n","            batch_size=BATCH_SIZE,\n","            augment=False,\n","            shuffle=False,\n","            repeat=False,\n","            cache=False,\n","        ),\n","        return_dict=True,\n","#        steps=NUM_VALID/BATCH_SIZE,\n","        verbose=1,\n","    )\n","    print()\n","    \n","    # Store valid results\n","    for fm in metrics:\n","        M[\"val_\" + fm].append(m[fm])\n","        \n","\n","    # Plot Training History\n","    if CFG.display_plot:\n","        plt.figure(figsize=(15, 5))\n","        plt.plot(\n","            np.arange(len(history[\"dice_coef\"])),\n","            history[\"dice_coef\"],\n","            \"-o\",\n","            label=\"Train Dice\",\n","            color=\"#ff7f0e\",\n","        )\n","        plt.plot(\n","            np.arange(len(history[\"dice_coef\"])),\n","            history[\"val_dice_coef\"],\n","            \"-o\",\n","            label=\"Val Dice\",\n","            color=\"#1f77b4\",\n","        )\n","        x = np.argmax(history[\"val_dice_coef\"])\n","        y = np.max(history[\"val_dice_coef\"])\n","        xdist = plt.xlim()[1] - plt.xlim()[0]\n","        ydist = plt.ylim()[1] - plt.ylim()[0]\n","        plt.scatter(x, y, s=200, color=\"#1f77b4\")\n","        plt.text(x - 0.03 * xdist, y - 0.13 * ydist, \"max dice\\n%.2f\" % y, size=14)\n","        plt.ylabel(\"dice_coef\", size=14)\n","        plt.xlabel(\"Epoch\", size=14)\n","        plt.legend(loc=2)\n","        plt2 = plt.gca().twinx()\n","        plt2.plot(\n","            np.arange(len(history[\"dice_coef\"])),\n","            history[\"loss\"],\n","            \"-o\",\n","            label=\"Train Loss\",\n","            color=\"#2ca02c\",\n","        )\n","        plt2.plot(\n","            np.arange(len(history[\"dice_coef\"])),\n","            history[\"val_loss\"],\n","            \"-o\",\n","            label=\"Val Loss\",\n","            color=\"#d62728\",\n","        )\n","        x = np.argmin(history[\"val_loss\"])\n","        y = np.min(history[\"val_loss\"])\n","        ydist = plt.ylim()[1] - plt.ylim()[0]\n","        plt.scatter(x, y, s=200, color=\"#d62728\")\n","        plt.text(x - 0.03 * xdist, y + 0.05 * ydist, \"min loss\", size=14)\n","        plt.ylabel(\"Loss\", size=14)\n","        plt.title(\"FOLD %i\" % (fold), size=18)\n","        plt.legend(loc=3)\n","        plt.savefig(f\"fig-{fold}.png\")\n","        plt.show()"]},{"cell_type":"markdown","id":"a33c2551","metadata":{"papermill":{"duration":0.170144,"end_time":"2022-06-04T08:13:36.105545","exception":false,"start_time":"2022-06-04T08:13:35.935401","status":"completed"},"tags":[],"id":"a33c2551"},"source":["## Training Log\n","### [Click Here âž¡ï¸](https://wandb.ai/awsaf49/uwmgi-tf) to check training log in **WandB** dashboard.\n","\n","<img src=\"https://i.ibb.co/V3XGd4r/wandb-dashboard.png\">"]},{"cell_type":"markdown","id":"5d5e08d4","metadata":{"papermill":{"duration":0.168424,"end_time":"2022-06-04T08:13:36.443437","exception":false,"start_time":"2022-06-04T08:13:36.275013","status":"completed"},"tags":[],"id":"5d5e08d4"},"source":["# 15. Calculate OOF ðŸ‘€\n","Let's check our average score across all folds. This will help us compare our model's performance."]},{"cell_type":"code","execution_count":null,"id":"c0bda25d","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-04T08:13:36.789108Z","iopub.status.busy":"2022-06-04T08:13:36.788406Z","iopub.status.idle":"2022-06-04T08:13:36.795939Z","shell.execute_reply":"2022-06-04T08:13:36.796487Z"},"papermill":{"duration":0.18158,"end_time":"2022-06-04T08:13:36.796656","exception":false,"start_time":"2022-06-04T08:13:36.615076","status":"completed"},"tags":[],"id":"c0bda25d","outputId":"014938f2-b988-410e-c1ab-c1164fe734fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["OOF loss: 0.59567990899086\n","OOF dice_coef: 0.7420103311538696\n","OOF precision: 0.45263837575912474\n","OOF recall: 0.7576842904090881\n"]}],"source":["# Save Metrics\n","M['datetime'] = str(datetime.now())\n","for fm in metrics:\n","    M['oof_'+fm] = np.mean(M['val_'+fm])\n","    print('OOF '+ fm + ': '+ str(M['oof_'+fm]))\n","with open('metrics.json', 'w') as outfile:\n","    json.dump(M, outfile)"]},{"cell_type":"markdown","id":"14c511ee","metadata":{"papermill":{"duration":0.171204,"end_time":"2022-06-04T08:13:37.139292","exception":false,"start_time":"2022-06-04T08:13:36.968088","status":"completed"},"tags":[],"id":"14c511ee"},"source":["# 16. Reference ðŸ’¡\n","* [Triple Stratified KFold with TFRecords](https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords) by [Chris Deotte](https://www.kaggle.com/cdeotte)\n","* [TransUNet](https://github.com/Beckschen/TransUNet)(Official)\n","* [TransUnet](https://github.com/kenza-bouzid/TransUnet)(Keras)"]},{"cell_type":"markdown","id":"b526edd4","metadata":{"papermill":{"duration":0.170473,"end_time":"2022-06-04T08:13:37.480314","exception":false,"start_time":"2022-06-04T08:13:37.309841","status":"completed"},"tags":[],"id":"b526edd4"},"source":["# 17. Remove Files âœ‚ï¸"]},{"cell_type":"code","execution_count":null,"id":"2ff5df5a","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-06-04T08:13:37.825465Z","iopub.status.busy":"2022-06-04T08:13:37.824834Z","iopub.status.idle":"2022-06-04T08:13:38.644315Z","shell.execute_reply":"2022-06-04T08:13:38.643701Z"},"papermill":{"duration":0.992457,"end_time":"2022-06-04T08:13:38.644466","exception":false,"start_time":"2022-06-04T08:13:37.652009","status":"completed"},"tags":[],"id":"2ff5df5a"},"outputs":[],"source":["import shutil\n","try:\n","    !rm -r ./wandb\n","except:\n","    pass"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":3034.763907,"end_time":"2022-06-04T08:13:41.532329","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-06-04T07:23:06.768422","version":"2.3.3"},"colab":{"name":"uwmgi-transunet-2-5d-train-tf.ipynb","provenance":[],"collapsed_sections":["a9a3759c","c9c90fa6","eae74778","962d7033","92c423b2","f810ea08","3d920646","3f9b00d0","5a1015a8","c54b28e7","500233b2","1f663d3f","6a9354e4","229abccc","cff4f14b","a6692364","bf7efab8","a33c2551","5d5e08d4","14c511ee","b526edd4"]},"accelerator":"TPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}